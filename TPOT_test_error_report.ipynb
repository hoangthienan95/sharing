{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n"
     ]
    }
   ],
   "source": [
    "#set ulimit to 10k before running notebook to accomodate num_df file descriptors. ~200 workers * 25 fd/worker = 5k\n",
    "!ulimit -n\n",
    "#!ulimit -Sn 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tpot import TPOTRegressor\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3327ccad1d394420b6dcda8c144f2363",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntProgress(value=10)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from ipywidgets import IntProgress\n",
    "IntProgress(10,max=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.9.5'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tpot\n",
    "tpot.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from dask.distributed import Client\n",
    "# client = Client(n_workers=4, threads_per_worker=1)\n",
    "# client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from dask_jobqueue import LSFCluster\n",
    "from dask.distributed import Client, progress\n",
    "from timeit import default_timer as timer\n",
    "import dask.bag as db\n",
    "import dask.dataframe as dd\n",
    "import gc\n",
    "# try:\n",
    "#     gc.enable()\n",
    "#     del cluster\n",
    "#     gc.collect(cluster)\n",
    "# except:\n",
    "#     pass\n",
    "# cluster = LSFCluster(queue='corradin_long',\n",
    "#                      cores= 2,\n",
    "#                      #ncpus=2,\n",
    "#                      walltime='1000000:00',\n",
    "#                      memory='15GB',\n",
    "#                      death_timeout=600,\n",
    "#                      job_extra=['-o /dev/null', '-g /dask-workers', '-e error_log_worker' ]#, '']\n",
    "#                      )\n",
    "# cluster.adapt(minimum= 200, maximum=200)\n",
    "# #cluster.scale(250)\n",
    "# print(cluster.job_script())\n",
    "# cluster.dashboard_link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pat_Enc_CSN_ID</th>\n",
       "      <th>ADT_Arrival_Time</th>\n",
       "      <th>EDDepartureDt</th>\n",
       "      <th>First_IP_BedRequestDt</th>\n",
       "      <th>LOS</th>\n",
       "      <th>timeToRoom</th>\n",
       "      <th>Age</th>\n",
       "      <th>ArrivalMethod</th>\n",
       "      <th>First_CareArea</th>\n",
       "      <th>Last_CareArea</th>\n",
       "      <th>...</th>\n",
       "      <th>PendingMed</th>\n",
       "      <th>PendingSurg</th>\n",
       "      <th>PendingICU</th>\n",
       "      <th>PendingAll_RequestTime</th>\n",
       "      <th>PendingMed_RequestTime</th>\n",
       "      <th>PendingSurg_RequestTime</th>\n",
       "      <th>PendingICU_RequestTime</th>\n",
       "      <th>ShareEDMedBedRequests_RequestTime</th>\n",
       "      <th>ShareEDSurgBedRequests_RequestTime</th>\n",
       "      <th>ShareEDICUBedRequests_RequestTime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3226269117</td>\n",
       "      <td>11/19/18 21:29</td>\n",
       "      <td>11/20/18 15:27</td>\n",
       "      <td>11/20/18 3:21</td>\n",
       "      <td>1078.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>80</td>\n",
       "      <td>Car</td>\n",
       "      <td>Evalulation</td>\n",
       "      <td>Urgent</td>\n",
       "      <td>...</td>\n",
       "      <td>123</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>346</td>\n",
       "      <td>120</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3226274255</td>\n",
       "      <td>11/20/18 4:15</td>\n",
       "      <td>11/20/18 15:08</td>\n",
       "      <td>11/20/18 5:35</td>\n",
       "      <td>653.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>71</td>\n",
       "      <td>Ambulance</td>\n",
       "      <td>Acute</td>\n",
       "      <td>Acute</td>\n",
       "      <td>...</td>\n",
       "      <td>126</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>352</td>\n",
       "      <td>123</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0.216561</td>\n",
       "      <td>0.238095</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3226636912</td>\n",
       "      <td>11/23/18 9:43</td>\n",
       "      <td>11/23/18 13:42</td>\n",
       "      <td>NaN</td>\n",
       "      <td>239.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>59</td>\n",
       "      <td>Public Transportation</td>\n",
       "      <td>Evalulation</td>\n",
       "      <td>CDU</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>344</td>\n",
       "      <td>119</td>\n",
       "      <td>14</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3226646686</td>\n",
       "      <td>11/23/18 10:56</td>\n",
       "      <td>11/23/18 21:07</td>\n",
       "      <td>11/23/18 13:34</td>\n",
       "      <td>611.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>55</td>\n",
       "      <td>Ambulance</td>\n",
       "      <td>Acute</td>\n",
       "      <td>Acute</td>\n",
       "      <td>...</td>\n",
       "      <td>131</td>\n",
       "      <td>18</td>\n",
       "      <td>6</td>\n",
       "      <td>390</td>\n",
       "      <td>149</td>\n",
       "      <td>21</td>\n",
       "      <td>6</td>\n",
       "      <td>0.050955</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3226655334</td>\n",
       "      <td>11/23/18 11:59</td>\n",
       "      <td>11/23/18 15:06</td>\n",
       "      <td>11/23/18 14:17</td>\n",
       "      <td>187.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6</td>\n",
       "      <td>Car</td>\n",
       "      <td>Pedi</td>\n",
       "      <td>Pedi</td>\n",
       "      <td>...</td>\n",
       "      <td>126</td>\n",
       "      <td>18</td>\n",
       "      <td>5</td>\n",
       "      <td>375</td>\n",
       "      <td>140</td>\n",
       "      <td>20</td>\n",
       "      <td>6</td>\n",
       "      <td>0.072848</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 76 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pat_Enc_CSN_ID ADT_Arrival_Time   EDDepartureDt First_IP_BedRequestDt  \\\n",
       "0      3226269117   11/19/18 21:29  11/20/18 15:27         11/20/18 3:21   \n",
       "1      3226274255    11/20/18 4:15  11/20/18 15:08         11/20/18 5:35   \n",
       "2      3226636912    11/23/18 9:43  11/23/18 13:42                   NaN   \n",
       "3      3226646686   11/23/18 10:56  11/23/18 21:07        11/23/18 13:34   \n",
       "4      3226655334   11/23/18 11:59  11/23/18 15:06        11/23/18 14:17   \n",
       "\n",
       "      LOS  timeToRoom  Age          ArrivalMethod First_CareArea  \\\n",
       "0  1078.0        45.0   80                    Car    Evalulation   \n",
       "1   653.0         7.0   71              Ambulance          Acute   \n",
       "2   239.0        19.0   59  Public Transportation    Evalulation   \n",
       "3   611.0         8.0   55              Ambulance          Acute   \n",
       "4   187.0         3.0    6                    Car           Pedi   \n",
       "\n",
       "  Last_CareArea                ...                  PendingMed  PendingSurg  \\\n",
       "0        Urgent                ...                         123           15   \n",
       "1         Acute                ...                         126           16   \n",
       "2           CDU                ...                           0            0   \n",
       "3         Acute                ...                         131           18   \n",
       "4          Pedi                ...                         126           18   \n",
       "\n",
       "  PendingICU PendingAll_RequestTime PendingMed_RequestTime  \\\n",
       "0          1                    346                    120   \n",
       "1          1                    352                    123   \n",
       "2          0                    344                    119   \n",
       "3          6                    390                    149   \n",
       "4          5                    375                    140   \n",
       "\n",
       "   PendingSurg_RequestTime  PendingICU_RequestTime  \\\n",
       "0                       15                       1   \n",
       "1                       16                       1   \n",
       "2                       14                       5   \n",
       "3                       21                       6   \n",
       "4                       20                       6   \n",
       "\n",
       "   ShareEDMedBedRequests_RequestTime  ShareEDSurgBedRequests_RequestTime  \\\n",
       "0                           0.200000                            0.285714   \n",
       "1                           0.216561                            0.238095   \n",
       "2                                NaN                                 NaN   \n",
       "3                           0.050955                            0.000000   \n",
       "4                           0.072848                            0.000000   \n",
       "\n",
       "   ShareEDICUBedRequests_RequestTime  \n",
       "0                           0.500000  \n",
       "1                           0.666667  \n",
       "2                                NaN  \n",
       "3                           0.000000  \n",
       "4                           0.000000  \n",
       "\n",
       "[5 rows x 76 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"ML_Features_March2018.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ADT_Arrival_Time',\n",
       " 'EDDepartureDt',\n",
       " 'First_IP_BedRequestDt',\n",
       " 'ArrivalMethod',\n",
       " 'First_CareArea',\n",
       " 'Last_CareArea',\n",
       " 'ActualLocationAfterED',\n",
       " 'First_EDAttending',\n",
       " 'ChiefComplaint',\n",
       " 'DispoGrp']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string_cols = [x for x in data.columns if data[x].dtypes == \"object\"]\n",
    "string_cols\n",
    "#string_cols = [data[x].astype(\"category\", copy=False) for x in string_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['LOS',\n",
       " 'timeToRoom',\n",
       " 'MedBedsUtil',\n",
       " 'SurgBedsUtil',\n",
       " 'ICUBedsUtil',\n",
       " 'OtherBedsUtil',\n",
       " 'MedBedsAvailable_RequestTime',\n",
       " 'SurgBedsAvailable_RequestTime',\n",
       " 'ICUBedsAvailable_RequestTime',\n",
       " 'OtherBedsAvailable_RequestTime',\n",
       " 'MedBedsUtil_RequestTime',\n",
       " 'SurgBedsUtil_RequestTime',\n",
       " 'ICUBedsUtil_RequestTime',\n",
       " 'OtherBedsUtil_RequestTime',\n",
       " 'EDMedBedRequests_RequestTime',\n",
       " 'EDSurgBedRequests_RequestTime',\n",
       " 'EDICUBedRequests_RequestTime',\n",
       " 'ShareEDMedBedRequests_RequestTime',\n",
       " 'ShareEDSurgBedRequests_RequestTime',\n",
       " 'ShareEDICUBedRequests_RequestTime']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float_cols = [x for x in data.columns if data[x].dtypes == \"float64\"]\n",
    "float_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pat_Enc_CSN_ID                           int64\n",
       "ADT_Arrival_Time                      category\n",
       "EDDepartureDt                         category\n",
       "First_IP_BedRequestDt                 category\n",
       "LOS                                    float64\n",
       "timeToRoom                             float64\n",
       "Age                                      int64\n",
       "ArrivalMethod                         category\n",
       "First_CareArea                        category\n",
       "Last_CareArea                         category\n",
       "DoW                                      int64\n",
       "ToD                                      int64\n",
       "ActualLocationAfterED                 category\n",
       "First_EDAttending                     category\n",
       "ChiefComplaint                        category\n",
       "AreaChange                               int64\n",
       "DoY                                      int64\n",
       "EDCensus                                 int64\n",
       "numUrgAcuteBoarders                      int64\n",
       "OBSFlg                                   int64\n",
       "DispoGrp                              category\n",
       "NumUrgAcuteDepartures                    int64\n",
       "EDOBSCensus                              int64\n",
       "AcuteCensus                              int64\n",
       "UrgentCensus                             int64\n",
       "FastTrackCensus                          int64\n",
       "PediCensus                               int64\n",
       "CDUCensus                                int64\n",
       "APSCensus                                int64\n",
       "NumOtherConsults                         int64\n",
       "                                        ...   \n",
       "MedBedsAvailable                         int64\n",
       "SurgBedsAvailable                        int64\n",
       "ICUBedsAvailable                         int64\n",
       "OtherBedsAvailable                       int64\n",
       "MedBedsUtil                            float64\n",
       "SurgBedsUtil                           float64\n",
       "ICUBedsUtil                            float64\n",
       "OtherBedsUtil                          float64\n",
       "MedBedsAvailable_RequestTime           float64\n",
       "SurgBedsAvailable_RequestTime          float64\n",
       "ICUBedsAvailable_RequestTime           float64\n",
       "OtherBedsAvailable_RequestTime         float64\n",
       "MedBedsUtil_RequestTime                float64\n",
       "SurgBedsUtil_RequestTime               float64\n",
       "ICUBedsUtil_RequestTime                float64\n",
       "OtherBedsUtil_RequestTime              float64\n",
       "EDMedBedRequests_RequestTime           float64\n",
       "EDSurgBedRequests_RequestTime          float64\n",
       "EDICUBedRequests_RequestTime           float64\n",
       "PendingAll                               int64\n",
       "PendingMed                               int64\n",
       "PendingSurg                              int64\n",
       "PendingICU                               int64\n",
       "PendingAll_RequestTime                   int64\n",
       "PendingMed_RequestTime                   int64\n",
       "PendingSurg_RequestTime                  int64\n",
       "PendingICU_RequestTime                   int64\n",
       "ShareEDMedBedRequests_RequestTime      float64\n",
       "ShareEDSurgBedRequests_RequestTime     float64\n",
       "ShareEDICUBedRequests_RequestTime      float64\n",
       "Length: 76, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for x in string_cols:\n",
    "#     data[x].astype(\"category\", copy=False)\n",
    "data[string_cols] = data[string_cols].astype(\"category\")\n",
    "data[float_cols] = data[float_cols].astype(np.float64)\n",
    "data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pat_Enc_CSN_ID                            0\n",
       "ADT_Arrival_Time                          0\n",
       "EDDepartureDt                            90\n",
       "First_IP_BedRequestDt                 16492\n",
       "LOS                                      90\n",
       "timeToRoom                              201\n",
       "Age                                       0\n",
       "ArrivalMethod                            18\n",
       "First_CareArea                          175\n",
       "Last_CareArea                           296\n",
       "DoW                                       0\n",
       "ToD                                       0\n",
       "ActualLocationAfterED                 16686\n",
       "First_EDAttending                       280\n",
       "ChiefComplaint                         2066\n",
       "AreaChange                                0\n",
       "DoY                                       0\n",
       "EDCensus                                  0\n",
       "numUrgAcuteBoarders                       0\n",
       "OBSFlg                                    0\n",
       "DispoGrp                                 90\n",
       "NumUrgAcuteDepartures                     0\n",
       "EDOBSCensus                               0\n",
       "AcuteCensus                               0\n",
       "UrgentCensus                              0\n",
       "FastTrackCensus                           0\n",
       "PediCensus                                0\n",
       "CDUCensus                                 0\n",
       "APSCensus                                 0\n",
       "NumOtherConsults                          0\n",
       "                                      ...  \n",
       "MedBedsAvailable                          0\n",
       "SurgBedsAvailable                         0\n",
       "ICUBedsAvailable                          0\n",
       "OtherBedsAvailable                        0\n",
       "MedBedsUtil                               0\n",
       "SurgBedsUtil                              0\n",
       "ICUBedsUtil                               0\n",
       "OtherBedsUtil                             0\n",
       "MedBedsAvailable_RequestTime          16492\n",
       "SurgBedsAvailable_RequestTime         16492\n",
       "ICUBedsAvailable_RequestTime          16492\n",
       "OtherBedsAvailable_RequestTime        16492\n",
       "MedBedsUtil_RequestTime               16492\n",
       "SurgBedsUtil_RequestTime              16492\n",
       "ICUBedsUtil_RequestTime               16492\n",
       "OtherBedsUtil_RequestTime             16492\n",
       "EDMedBedRequests_RequestTime          16492\n",
       "EDSurgBedRequests_RequestTime         16492\n",
       "EDICUBedRequests_RequestTime          16492\n",
       "PendingAll                                0\n",
       "PendingMed                                0\n",
       "PendingSurg                               0\n",
       "PendingICU                                0\n",
       "PendingAll_RequestTime                    0\n",
       "PendingMed_RequestTime                    0\n",
       "PendingSurg_RequestTime                   0\n",
       "PendingICU_RequestTime                    0\n",
       "ShareEDMedBedRequests_RequestTime     16492\n",
       "ShareEDSurgBedRequests_RequestTime    16492\n",
       "ShareEDICUBedRequests_RequestTime     16492\n",
       "Length: 76, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ActualLocationAfterED',\n",
       " 'EDICUBedRequests_RequestTime',\n",
       " 'EDMedBedRequests_RequestTime',\n",
       " 'EDSurgBedRequests_RequestTime',\n",
       " 'First_IP_BedRequestDt',\n",
       " 'ICUBedsAvailable_RequestTime',\n",
       " 'ICUBedsUtil_RequestTime',\n",
       " 'MedBedsAvailable_RequestTime',\n",
       " 'MedBedsUtil_RequestTime',\n",
       " 'OtherBedsAvailable_RequestTime',\n",
       " 'OtherBedsUtil_RequestTime',\n",
       " 'ShareEDICUBedRequests_RequestTime',\n",
       " 'ShareEDMedBedRequests_RequestTime',\n",
       " 'ShareEDSurgBedRequests_RequestTime',\n",
       " 'SurgBedsAvailable_RequestTime',\n",
       " 'SurgBedsUtil_RequestTime'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns_pre_filter = set(data.columns)\n",
    "columns_post_filter = set(data.dropna(axis = 1, thresh=data.shape[0] * 0.9).columns)\n",
    "columns_filtered = columns_pre_filter - columns_post_filter\n",
    "columns_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22258, 60)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_data = data[list(columns_post_filter)]\n",
    "filtered_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EDOBSCensus</th>\n",
       "      <th>NumCT</th>\n",
       "      <th>LOS</th>\n",
       "      <th>DoY</th>\n",
       "      <th>CDUCensus</th>\n",
       "      <th>OtF</th>\n",
       "      <th>ChiefComplaint</th>\n",
       "      <th>OtP</th>\n",
       "      <th>NumUS</th>\n",
       "      <th>ICUBedsAvailable</th>\n",
       "      <th>...</th>\n",
       "      <th>PendingSurg</th>\n",
       "      <th>APSCensus</th>\n",
       "      <th>NumScans</th>\n",
       "      <th>OtherBedsAvailable</th>\n",
       "      <th>Last_CareArea</th>\n",
       "      <th>PediCensus</th>\n",
       "      <th>UrgentAndAcuteWaitingForAdmit</th>\n",
       "      <th>ICUBedsUtil</th>\n",
       "      <th>DoW</th>\n",
       "      <th>NumSurgConsults</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>1078.0</td>\n",
       "      <td>-323</td>\n",
       "      <td>31</td>\n",
       "      <td>88</td>\n",
       "      <td>WEIGHT LOSS</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>15</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>208</td>\n",
       "      <td>Urgent</td>\n",
       "      <td>12</td>\n",
       "      <td>24</td>\n",
       "      <td>0.098765</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>653.0</td>\n",
       "      <td>-324</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>DIVERTICULITIS</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>16</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>203</td>\n",
       "      <td>Acute</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>0.101266</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>239.0</td>\n",
       "      <td>-327</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>MIGRAINE</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>228</td>\n",
       "      <td>CDU</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>611.0</td>\n",
       "      <td>-327</td>\n",
       "      <td>10</td>\n",
       "      <td>21</td>\n",
       "      <td>CHEST PAIN</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>18</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>211</td>\n",
       "      <td>Acute</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>0.075949</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>187.0</td>\n",
       "      <td>-327</td>\n",
       "      <td>15</td>\n",
       "      <td>223</td>\n",
       "      <td>ABDOMINAL PAIN</td>\n",
       "      <td>148</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>18</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>207</td>\n",
       "      <td>Pedi</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.075949</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 57 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   EDOBSCensus  NumCT     LOS  DoY  CDUCensus  OtF  ChiefComplaint  OtP  \\\n",
       "0           25      0  1078.0 -323         31   88     WEIGHT LOSS    0   \n",
       "1           28      0   653.0 -324         23    0  DIVERTICULITIS    0   \n",
       "2           17      0   239.0 -327          7    0        MIGRAINE    0   \n",
       "3           16      0   611.0 -327         10   21      CHEST PAIN   17   \n",
       "4           16      0   187.0 -327         15  223  ABDOMINAL PAIN  148   \n",
       "\n",
       "   NumUS  ICUBedsAvailable       ...         PendingSurg  APSCensus  NumScans  \\\n",
       "0      0                 8       ...                  15          5         1   \n",
       "1      0                 8       ...                  16          6         0   \n",
       "2      0                 8       ...                   0          4         0   \n",
       "3      0                 6       ...                  18          5         1   \n",
       "4      1                 6       ...                  18          5         1   \n",
       "\n",
       "   OtherBedsAvailable  Last_CareArea  PediCensus  \\\n",
       "0                 208         Urgent          12   \n",
       "1                 203          Acute           0   \n",
       "2                 228            CDU           1   \n",
       "3                 211          Acute           1   \n",
       "4                 207           Pedi           2   \n",
       "\n",
       "   UrgentAndAcuteWaitingForAdmit ICUBedsUtil  DoW  NumSurgConsults  \n",
       "0                             24    0.098765    2                0  \n",
       "1                             42    0.101266    3                1  \n",
       "2                             12    0.100000    6                0  \n",
       "3                             10    0.075949    6                0  \n",
       "4                             10    0.075949    6                1  \n",
       "\n",
       "[5 rows x 57 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_data = filtered_data.drop(columns=[\"Pat_Enc_CSN_ID\", \"ADT_Arrival_Time\", \"EDDepartureDt\"])#, \"First_IP_BedRequestDt\"])\n",
    "filtered_data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22258, 57)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummied = filtered_data.copy()\n",
    "dummied.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19889, 57)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummied = dummied[~dummied.isna().any(axis=1)]\n",
    "dummied.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EDOBSCensus</th>\n",
       "      <th>NumCT</th>\n",
       "      <th>LOS</th>\n",
       "      <th>DoY</th>\n",
       "      <th>CDUCensus</th>\n",
       "      <th>OtF</th>\n",
       "      <th>OtP</th>\n",
       "      <th>NumUS</th>\n",
       "      <th>ICUBedsAvailable</th>\n",
       "      <th>OtherBedsUtil</th>\n",
       "      <th>...</th>\n",
       "      <th>ArrivalMethod_nan</th>\n",
       "      <th>Last_CareArea_APS</th>\n",
       "      <th>Last_CareArea_Acute</th>\n",
       "      <th>Last_CareArea_CDU</th>\n",
       "      <th>Last_CareArea_Evalulation</th>\n",
       "      <th>Last_CareArea_Fast Track</th>\n",
       "      <th>Last_CareArea_Pedi</th>\n",
       "      <th>Last_CareArea_Surge</th>\n",
       "      <th>Last_CareArea_Urgent</th>\n",
       "      <th>Last_CareArea_nan</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>1078.0</td>\n",
       "      <td>-323</td>\n",
       "      <td>31</td>\n",
       "      <td>88</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0.371429</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>653.0</td>\n",
       "      <td>-324</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0.362500</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>239.0</td>\n",
       "      <td>-327</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0.402827</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>611.0</td>\n",
       "      <td>-327</td>\n",
       "      <td>10</td>\n",
       "      <td>21</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0.370826</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>187.0</td>\n",
       "      <td>-327</td>\n",
       "      <td>15</td>\n",
       "      <td>223</td>\n",
       "      <td>148</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0.364437</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 640 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   EDOBSCensus  NumCT     LOS  DoY  CDUCensus  OtF  OtP  NumUS  \\\n",
       "0           25      0  1078.0 -323         31   88    0      0   \n",
       "1           28      0   653.0 -324         23    0    0      0   \n",
       "2           17      0   239.0 -327          7    0    0      0   \n",
       "3           16      0   611.0 -327         10   21   17      0   \n",
       "4           16      0   187.0 -327         15  223  148      1   \n",
       "\n",
       "   ICUBedsAvailable  OtherBedsUtil        ...          ArrivalMethod_nan  \\\n",
       "0                 8       0.371429        ...                          0   \n",
       "1                 8       0.362500        ...                          0   \n",
       "2                 8       0.402827        ...                          0   \n",
       "3                 6       0.370826        ...                          0   \n",
       "4                 6       0.364437        ...                          0   \n",
       "\n",
       "   Last_CareArea_APS  Last_CareArea_Acute  Last_CareArea_CDU  \\\n",
       "0                  0                    0                  0   \n",
       "1                  0                    1                  0   \n",
       "2                  0                    0                  1   \n",
       "3                  0                    1                  0   \n",
       "4                  0                    0                  0   \n",
       "\n",
       "   Last_CareArea_Evalulation  Last_CareArea_Fast Track  Last_CareArea_Pedi  \\\n",
       "0                          0                         0                   0   \n",
       "1                          0                         0                   0   \n",
       "2                          0                         0                   0   \n",
       "3                          0                         0                   0   \n",
       "4                          0                         0                   1   \n",
       "\n",
       "   Last_CareArea_Surge  Last_CareArea_Urgent  Last_CareArea_nan  \n",
       "0                    0                     1                  0  \n",
       "1                    0                     0                  0  \n",
       "2                    0                     0                  0  \n",
       "3                    0                     0                  0  \n",
       "4                    0                     0                  0  \n",
       "\n",
       "[5 rows x 640 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummied = pd.get_dummies(dummied, dummy_na=True)\n",
    "dummied.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EDOBSCensus                              int64\n",
       "NumCT                                    int64\n",
       "LOS                                    float64\n",
       "DoY                                      int64\n",
       "CDUCensus                                int64\n",
       "OtF                                      int64\n",
       "OtP                                      int64\n",
       "NumUS                                    int64\n",
       "ICUBedsAvailable                         int64\n",
       "OtherBedsUtil                          float64\n",
       "ToD                                      int64\n",
       "SurgBedsAvailable                        int64\n",
       "EDCensus                                 int64\n",
       "NumUrgAcuteDepartures                    int64\n",
       "NumXR                                    int64\n",
       "NumMR                                    int64\n",
       "NumLabsOrdered                           int64\n",
       "PendingICU                               int64\n",
       "SurgBedsUtil                           float64\n",
       "UrgentCensus                             int64\n",
       "PendingMed_RequestTime                   int64\n",
       "AreaChange                               int64\n",
       "numUrgAcuteBoarders                      int64\n",
       "NumNeuroConsults                         int64\n",
       "NumLabsResulted                          int64\n",
       "PendingAll_RequestTime                   int64\n",
       "PendingSurg_RequestTime                  int64\n",
       "PendingICU_RequestTime                   int64\n",
       "AcuteCensus                              int64\n",
       "PendingMed                               int64\n",
       "                                        ...   \n",
       "DispoGrp_Skilled Nursing Facility        uint8\n",
       "DispoGrp_nan                             uint8\n",
       "First_CareArea_APS                       uint8\n",
       "First_CareArea_Acute                     uint8\n",
       "First_CareArea_CDU                       uint8\n",
       "First_CareArea_Evalulation               uint8\n",
       "First_CareArea_Fast Track                uint8\n",
       "First_CareArea_Pedi                      uint8\n",
       "First_CareArea_Urgent                    uint8\n",
       "First_CareArea_nan                       uint8\n",
       "ArrivalMethod_Ambulance                  uint8\n",
       "ArrivalMethod_Assist From Vehicle        uint8\n",
       "ArrivalMethod_Car                        uint8\n",
       "ArrivalMethod_Hospital Transport         uint8\n",
       "ArrivalMethod_Medical Flight             uint8\n",
       "ArrivalMethod_Other                      uint8\n",
       "ArrivalMethod_Police                     uint8\n",
       "ArrivalMethod_Public Transportation      uint8\n",
       "ArrivalMethod_Taxi                       uint8\n",
       "ArrivalMethod_Wheelchair                 uint8\n",
       "ArrivalMethod_nan                        uint8\n",
       "Last_CareArea_APS                        uint8\n",
       "Last_CareArea_Acute                      uint8\n",
       "Last_CareArea_CDU                        uint8\n",
       "Last_CareArea_Evalulation                uint8\n",
       "Last_CareArea_Fast Track                 uint8\n",
       "Last_CareArea_Pedi                       uint8\n",
       "Last_CareArea_Surge                      uint8\n",
       "Last_CareArea_Urgent                     uint8\n",
       "Last_CareArea_nan                        uint8\n",
       "Length: 640, dtype: object"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummied.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    dummied.drop(columns=\"LOS\").values,\n",
    "    dummied.LOS.values,\n",
    "    train_size=0.8,\n",
    "    test_size=0.2,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Attempt 1: using 2 cores/worker, 200 workers, n_jobs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#!/bin/bash\n",
      "\n",
      "#BSUB -J dask-worker\n",
      "#BSUB -q corradin_long\n",
      "#BSUB -n 2\n",
      "#BSUB -R \"span[hosts=1]\"\n",
      "#BSUB -M 15000\n",
      "#BSUB -W 100000:00\n",
      "#BSUB -o /dev/null\n",
      "#BSUB -g /dask-workers\n",
      "#BSUB -e /dev/null\n",
      "JOB_ID=${LSB_JOBID%.*}\n",
      "\n",
      "\n",
      "\n",
      "/home/anhoang/.conda/envs/dask-test/bin/python -m distributed.cli.dask_worker tcp://172.18.10.1:35037 --nthreads 2 --memory-limit 15.00GB --name dask-worker--${JOB_ID}-- --death-timeout 600\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'http://172.18.10.1:8787/status'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dask_jobqueue import LSFCluster\n",
    "from dask.distributed import Client, progress\n",
    "from timeit import default_timer as timer\n",
    "import dask.bag as db\n",
    "import dask.dataframe as dd\n",
    "import gc\n",
    "try:\n",
    "    gc.enable()\n",
    "    del cluster\n",
    "    gc.collect(cluster)\n",
    "except:\n",
    "    pass\n",
    "cluster = LSFCluster(queue='corradin_long',\n",
    "                     cores= 2,\n",
    "                     #ncpus=2,\n",
    "                     walltime='100000:00',\n",
    "                     memory='15GB',\n",
    "                     death_timeout=600,\n",
    "                     job_extra=['-o /dev/null', '-g /dask-workers', '-e error_log_worker' ]#, '']\n",
    "                     )\n",
    "cluster.adapt(minimum= 200, maximum=200)\n",
    "#cluster.scale(250)\n",
    "print(cluster.job_script())\n",
    "cluster.dashboard_link\n",
    "client = Client(cluster)\n",
    "client\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale up: Increase the TPOT parameters like population_size, generations\n",
    "tp = TPOTRegressor(\n",
    "#     generations=2,\n",
    "    population_size=1000,\n",
    "#     cv=2,\n",
    "    n_jobs=100,\n",
    "    warm_start=True,\n",
    "    random_state=0,\n",
    "    verbosity=3,\n",
    "    periodic_checkpoint_folder = \"./tpot_checkpoints\",\n",
    "    memory = \"./memory\",\n",
    "    use_dask=True,\n",
    "    #config_dict = 'TPOT sparse'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"border: 2px solid white;\">\n",
       "<tr>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3>Client</h3>\n",
       "<ul>\n",
       "  <li><b>Scheduler: </b>tcp://172.18.10.1:35037\n",
       "  <li><b>Dashboard: </b><a href='http://172.18.10.1:8787/status' target='_blank'>http://172.18.10.1:8787/status</a>\n",
       "</ul>\n",
       "</td>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3>Cluster</h3>\n",
       "<ul>\n",
       "  <li><b>Workers: </b>200</li>\n",
       "  <li><b>Cores: </b>400</li>\n",
       "  <li><b>Memory: </b>3.00 TB</li>\n",
       "</ul>\n",
       "</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Client: scheduler='tcp://172.18.10.1:35037' processes=200 cores=400>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29 operators have been imported by TPOT.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e8f6b5155c94886a1f11ab8c905d7d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Optimization Progress', max=101000, style=ProgressStyle(descr…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Worker tcp://172.18.113.7:41473 restart in Job 7063541. This can be due to memory issue.\n",
      "Worker tcp://172.18.113.7:37111 restart in Job 7063643. This can be due to memory issue.\n",
      "Worker tcp://172.18.113.10:33667 restart in Job 7063655. This can be due to memory issue.\n",
      "Worker tcp://172.18.113.11:41213 restart in Job 7063659. This can be due to memory issue.\n",
      "Worker tcp://172.18.113.8:37241 restart in Job 7063673. This can be due to memory issue.\n",
      "Worker tcp://172.18.113.9:35103 restart in Job 7063671. This can be due to memory issue.\n",
      "Worker tcp://172.18.113.6:32999 restart in Job 7063592. This can be due to memory issue.\n",
      "Worker tcp://172.18.113.6:32861 restart in Job 7063661. This can be due to memory issue.\n",
      "Worker tcp://172.18.113.6:32861 restart in Job 7063661. This can be due to memory issue.\n",
      "Worker tcp://172.18.113.6:32999 restart in Job 7063592. This can be due to memory issue.\n",
      "Worker tcp://172.18.113.1:40805 restart in Job 7063675. This can be due to memory issue.\n",
      "Worker tcp://172.18.113.7:42625 restart in Job 7063698. This can be due to memory issue.\n",
      "Worker tcp://172.18.113.7:36589 restart in Job 7063614. This can be due to memory issue.\n",
      "Worker tcp://172.18.113.7:33979 restart in Job 7063665. This can be due to memory issue.\n",
      "Worker tcp://172.18.113.7:37735 restart in Job 7063636. This can be due to memory issue.\n",
      "distributed.utils - ERROR - Worker already exists tcp://172.18.113.5:34181\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/anhoang/.conda/envs/dask-test/lib/python3.6/site-packages/distributed/utils.py\", line 649, in log_errors\n",
      "    yield\n",
      "  File \"/home/anhoang/.conda/envs/dask-test/lib/python3.6/site-packages/distributed/scheduler.py\", line 1281, in add_worker\n",
      "    raise ValueError(\"Worker already exists %s\" % address)\n",
      "ValueError: Worker already exists tcp://172.18.113.5:34181\n",
      "distributed.core - ERROR - Worker already exists tcp://172.18.113.5:34181\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/anhoang/.conda/envs/dask-test/lib/python3.6/site-packages/distributed/core.py\", line 346, in handle_comm\n",
      "    result = yield result\n",
      "  File \"/home/anhoang/.conda/envs/dask-test/lib/python3.6/site-packages/tornado/gen.py\", line 1133, in run\n",
      "    value = future.result()\n",
      "  File \"/home/anhoang/.conda/envs/dask-test/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/home/anhoang/.conda/envs/dask-test/lib/python3.6/site-packages/distributed/scheduler.py\", line 1281, in add_worker\n",
      "    raise ValueError(\"Worker already exists %s\" % address)\n",
      "ValueError: Worker already exists tcp://172.18.113.5:34181\n",
      "distributed.utils - ERROR - Worker already exists tcp://172.18.113.5:35607\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/anhoang/.conda/envs/dask-test/lib/python3.6/site-packages/distributed/utils.py\", line 649, in log_errors\n",
      "    yield\n",
      "  File \"/home/anhoang/.conda/envs/dask-test/lib/python3.6/site-packages/distributed/scheduler.py\", line 1281, in add_worker\n",
      "    raise ValueError(\"Worker already exists %s\" % address)\n",
      "ValueError: Worker already exists tcp://172.18.113.5:35607\n",
      "distributed.core - ERROR - Worker already exists tcp://172.18.113.5:35607\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/anhoang/.conda/envs/dask-test/lib/python3.6/site-packages/distributed/core.py\", line 346, in handle_comm\n",
      "    result = yield result\n",
      "  File \"/home/anhoang/.conda/envs/dask-test/lib/python3.6/site-packages/tornado/gen.py\", line 1133, in run\n",
      "    value = future.result()\n",
      "  File \"/home/anhoang/.conda/envs/dask-test/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/home/anhoang/.conda/envs/dask-test/lib/python3.6/site-packages/distributed/scheduler.py\", line 1281, in add_worker\n",
      "    raise ValueError(\"Worker already exists %s\" % address)\n",
      "ValueError: Worker already exists tcp://172.18.113.5:35607\n",
      "distributed.utils - ERROR - Worker already exists tcp://172.18.113.5:46873\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/anhoang/.conda/envs/dask-test/lib/python3.6/site-packages/distributed/utils.py\", line 649, in log_errors\n",
      "    yield\n",
      "  File \"/home/anhoang/.conda/envs/dask-test/lib/python3.6/site-packages/distributed/scheduler.py\", line 1281, in add_worker\n",
      "    raise ValueError(\"Worker already exists %s\" % address)\n",
      "ValueError: Worker already exists tcp://172.18.113.5:46873\n",
      "distributed.core - ERROR - Worker already exists tcp://172.18.113.5:46873\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/anhoang/.conda/envs/dask-test/lib/python3.6/site-packages/distributed/core.py\", line 346, in handle_comm\n",
      "    result = yield result\n",
      "  File \"/home/anhoang/.conda/envs/dask-test/lib/python3.6/site-packages/tornado/gen.py\", line 1133, in run\n",
      "    value = future.result()\n",
      "  File \"/home/anhoang/.conda/envs/dask-test/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/home/anhoang/.conda/envs/dask-test/lib/python3.6/site-packages/distributed/scheduler.py\", line 1281, in add_worker\n",
      "    raise ValueError(\"Worker already exists %s\" % address)\n",
      "ValueError: Worker already exists tcp://172.18.113.5:46873\n",
      "distributed.utils - ERROR - Worker already exists tcp://172.18.113.9:38499\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/anhoang/.conda/envs/dask-test/lib/python3.6/site-packages/distributed/utils.py\", line 649, in log_errors\n",
      "    yield\n",
      "  File \"/home/anhoang/.conda/envs/dask-test/lib/python3.6/site-packages/distributed/scheduler.py\", line 1281, in add_worker\n",
      "    raise ValueError(\"Worker already exists %s\" % address)\n",
      "ValueError: Worker already exists tcp://172.18.113.9:38499\n",
      "distributed.core - ERROR - Worker already exists tcp://172.18.113.9:38499\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/anhoang/.conda/envs/dask-test/lib/python3.6/site-packages/distributed/core.py\", line 346, in handle_comm\n",
      "    result = yield result\n",
      "  File \"/home/anhoang/.conda/envs/dask-test/lib/python3.6/site-packages/tornado/gen.py\", line 1133, in run\n",
      "    value = future.result()\n",
      "  File \"/home/anhoang/.conda/envs/dask-test/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/home/anhoang/.conda/envs/dask-test/lib/python3.6/site-packages/distributed/scheduler.py\", line 1281, in add_worker\n",
      "    raise ValueError(\"Worker already exists %s\" % address)\n",
      "ValueError: Worker already exists tcp://172.18.113.9:38499\n",
      "Worker tcp://172.18.113.2:44023 restart in Job 7063599. This can be due to memory issue.\n",
      "Worker tcp://172.18.113.8:44465 restart in Job 7063621. This can be due to memory issue.\n",
      "Worker tcp://172.18.113.4:41531 restart in Job 7063679. This can be due to memory issue.\n",
      "Worker tcp://172.18.113.4:40669 restart in Job 7063668. This can be due to memory issue.\n",
      "Worker tcp://172.18.113.4:40915 restart in Job 7063545. This can be due to memory issue.\n",
      "distributed.utils - ERROR - Worker already exists tcp://172.18.113.11:35137\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/anhoang/.conda/envs/dask-test/lib/python3.6/site-packages/distributed/utils.py\", line 649, in log_errors\n",
      "    yield\n",
      "  File \"/home/anhoang/.conda/envs/dask-test/lib/python3.6/site-packages/distributed/scheduler.py\", line 1281, in add_worker\n",
      "    raise ValueError(\"Worker already exists %s\" % address)\n",
      "ValueError: Worker already exists tcp://172.18.113.11:35137\n",
      "distributed.core - ERROR - Worker already exists tcp://172.18.113.11:35137\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/anhoang/.conda/envs/dask-test/lib/python3.6/site-packages/distributed/core.py\", line 346, in handle_comm\n",
      "    result = yield result\n",
      "  File \"/home/anhoang/.conda/envs/dask-test/lib/python3.6/site-packages/tornado/gen.py\", line 1133, in run\n",
      "    value = future.result()\n",
      "  File \"/home/anhoang/.conda/envs/dask-test/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/home/anhoang/.conda/envs/dask-test/lib/python3.6/site-packages/distributed/scheduler.py\", line 1281, in add_worker\n",
      "    raise ValueError(\"Worker already exists %s\" % address)\n",
      "ValueError: Worker already exists tcp://172.18.113.11:35137\n",
      "distributed.utils - ERROR - Worker already exists tcp://172.18.113.11:40613\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/anhoang/.conda/envs/dask-test/lib/python3.6/site-packages/distributed/utils.py\", line 649, in log_errors\n",
      "    yield\n",
      "  File \"/home/anhoang/.conda/envs/dask-test/lib/python3.6/site-packages/distributed/scheduler.py\", line 1281, in add_worker\n",
      "    raise ValueError(\"Worker already exists %s\" % address)\n",
      "ValueError: Worker already exists tcp://172.18.113.11:40613\n",
      "distributed.core - ERROR - Worker already exists tcp://172.18.113.11:40613\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/anhoang/.conda/envs/dask-test/lib/python3.6/site-packages/distributed/core.py\", line 346, in handle_comm\n",
      "    result = yield result\n",
      "  File \"/home/anhoang/.conda/envs/dask-test/lib/python3.6/site-packages/tornado/gen.py\", line 1133, in run\n",
      "    value = future.result()\n",
      "  File \"/home/anhoang/.conda/envs/dask-test/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/home/anhoang/.conda/envs/dask-test/lib/python3.6/site-packages/distributed/scheduler.py\", line 1281, in add_worker\n",
      "    raise ValueError(\"Worker already exists %s\" % address)\n",
      "ValueError: Worker already exists tcp://172.18.113.11:40613\n",
      "distributed.utils - ERROR - Worker already exists tcp://172.18.113.10:39727\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/anhoang/.conda/envs/dask-test/lib/python3.6/site-packages/distributed/utils.py\", line 649, in log_errors\n",
      "    yield\n",
      "  File \"/home/anhoang/.conda/envs/dask-test/lib/python3.6/site-packages/distributed/scheduler.py\", line 1281, in add_worker\n",
      "    raise ValueError(\"Worker already exists %s\" % address)\n",
      "ValueError: Worker already exists tcp://172.18.113.10:39727\n",
      "distributed.core - ERROR - Worker already exists tcp://172.18.113.10:39727\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/anhoang/.conda/envs/dask-test/lib/python3.6/site-packages/distributed/core.py\", line 346, in handle_comm\n",
      "    result = yield result\n",
      "  File \"/home/anhoang/.conda/envs/dask-test/lib/python3.6/site-packages/tornado/gen.py\", line 1133, in run\n",
      "    value = future.result()\n",
      "  File \"/home/anhoang/.conda/envs/dask-test/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/home/anhoang/.conda/envs/dask-test/lib/python3.6/site-packages/distributed/scheduler.py\", line 1281, in add_worker\n",
      "    raise ValueError(\"Worker already exists %s\" % address)\n",
      "ValueError: Worker already exists tcp://172.18.113.10:39727\n",
      "distributed.utils - ERROR - Worker already exists tcp://172.18.113.10:42895\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/anhoang/.conda/envs/dask-test/lib/python3.6/site-packages/distributed/utils.py\", line 649, in log_errors\n",
      "    yield\n",
      "  File \"/home/anhoang/.conda/envs/dask-test/lib/python3.6/site-packages/distributed/scheduler.py\", line 1281, in add_worker\n",
      "    raise ValueError(\"Worker already exists %s\" % address)\n",
      "ValueError: Worker already exists tcp://172.18.113.10:42895\n",
      "distributed.core - ERROR - Worker already exists tcp://172.18.113.10:42895\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/anhoang/.conda/envs/dask-test/lib/python3.6/site-packages/distributed/core.py\", line 346, in handle_comm\n",
      "    result = yield result\n",
      "  File \"/home/anhoang/.conda/envs/dask-test/lib/python3.6/site-packages/tornado/gen.py\", line 1133, in run\n",
      "    value = future.result()\n",
      "  File \"/home/anhoang/.conda/envs/dask-test/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/home/anhoang/.conda/envs/dask-test/lib/python3.6/site-packages/distributed/scheduler.py\", line 1281, in add_worker\n",
      "    raise ValueError(\"Worker already exists %s\" % address)\n",
      "ValueError: Worker already exists tcp://172.18.113.10:42895\n",
      "distributed.utils - ERROR - Worker already exists tcp://172.18.113.10:41647\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/anhoang/.conda/envs/dask-test/lib/python3.6/site-packages/distributed/utils.py\", line 649, in log_errors\n",
      "    yield\n",
      "  File \"/home/anhoang/.conda/envs/dask-test/lib/python3.6/site-packages/distributed/scheduler.py\", line 1281, in add_worker\n",
      "    raise ValueError(\"Worker already exists %s\" % address)\n",
      "ValueError: Worker already exists tcp://172.18.113.10:41647\n",
      "distributed.core - ERROR - Worker already exists tcp://172.18.113.10:41647\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/anhoang/.conda/envs/dask-test/lib/python3.6/site-packages/distributed/core.py\", line 346, in handle_comm\n",
      "    result = yield result\n",
      "  File \"/home/anhoang/.conda/envs/dask-test/lib/python3.6/site-packages/tornado/gen.py\", line 1133, in run\n",
      "    value = future.result()\n",
      "  File \"/home/anhoang/.conda/envs/dask-test/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/home/anhoang/.conda/envs/dask-test/lib/python3.6/site-packages/distributed/scheduler.py\", line 1281, in add_worker\n",
      "    raise ValueError(\"Worker already exists %s\" % address)\n",
      "ValueError: Worker already exists tcp://172.18.113.10:41647\n",
      "distributed.utils - ERROR - Worker already exists tcp://172.18.113.10:46153\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/anhoang/.conda/envs/dask-test/lib/python3.6/site-packages/distributed/utils.py\", line 649, in log_errors\n",
      "    yield\n",
      "  File \"/home/anhoang/.conda/envs/dask-test/lib/python3.6/site-packages/distributed/scheduler.py\", line 1281, in add_worker\n",
      "    raise ValueError(\"Worker already exists %s\" % address)\n",
      "ValueError: Worker already exists tcp://172.18.113.10:46153\n",
      "distributed.core - ERROR - Worker already exists tcp://172.18.113.10:46153\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/anhoang/.conda/envs/dask-test/lib/python3.6/site-packages/distributed/core.py\", line 346, in handle_comm\n",
      "    result = yield result\n",
      "  File \"/home/anhoang/.conda/envs/dask-test/lib/python3.6/site-packages/tornado/gen.py\", line 1133, in run\n",
      "    value = future.result()\n",
      "  File \"/home/anhoang/.conda/envs/dask-test/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/home/anhoang/.conda/envs/dask-test/lib/python3.6/site-packages/distributed/scheduler.py\", line 1281, in add_worker\n",
      "    raise ValueError(\"Worker already exists %s\" % address)\n",
      "ValueError: Worker already exists tcp://172.18.113.10:46153\n",
      "distributed.utils - ERROR - Worker already exists tcp://172.18.113.10:38653\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/anhoang/.conda/envs/dask-test/lib/python3.6/site-packages/distributed/utils.py\", line 649, in log_errors\n",
      "    yield\n",
      "  File \"/home/anhoang/.conda/envs/dask-test/lib/python3.6/site-packages/distributed/scheduler.py\", line 1281, in add_worker\n",
      "    raise ValueError(\"Worker already exists %s\" % address)\n",
      "ValueError: Worker already exists tcp://172.18.113.10:38653\n",
      "distributed.core - ERROR - Worker already exists tcp://172.18.113.10:38653\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/anhoang/.conda/envs/dask-test/lib/python3.6/site-packages/distributed/core.py\", line 346, in handle_comm\n",
      "    result = yield result\n",
      "  File \"/home/anhoang/.conda/envs/dask-test/lib/python3.6/site-packages/tornado/gen.py\", line 1133, in run\n",
      "    value = future.result()\n",
      "  File \"/home/anhoang/.conda/envs/dask-test/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/home/anhoang/.conda/envs/dask-test/lib/python3.6/site-packages/distributed/scheduler.py\", line 1281, in add_worker\n",
      "    raise ValueError(\"Worker already exists %s\" % address)\n",
      "ValueError: Worker already exists tcp://172.18.113.10:38653\n",
      "distributed.utils - ERROR - Worker already exists tcp://172.18.113.3:34863\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/anhoang/.conda/envs/dask-test/lib/python3.6/site-packages/distributed/utils.py\", line 649, in log_errors\n",
      "    yield\n",
      "  File \"/home/anhoang/.conda/envs/dask-test/lib/python3.6/site-packages/distributed/scheduler.py\", line 1281, in add_worker\n",
      "    raise ValueError(\"Worker already exists %s\" % address)\n",
      "ValueError: Worker already exists tcp://172.18.113.3:34863\n",
      "distributed.core - ERROR - Worker already exists tcp://172.18.113.3:34863\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/anhoang/.conda/envs/dask-test/lib/python3.6/site-packages/distributed/core.py\", line 346, in handle_comm\n",
      "    result = yield result\n",
      "  File \"/home/anhoang/.conda/envs/dask-test/lib/python3.6/site-packages/tornado/gen.py\", line 1133, in run\n",
      "    value = future.result()\n",
      "  File \"/home/anhoang/.conda/envs/dask-test/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/home/anhoang/.conda/envs/dask-test/lib/python3.6/site-packages/distributed/scheduler.py\", line 1281, in add_worker\n",
      "    raise ValueError(\"Worker already exists %s\" % address)\n",
      "ValueError: Worker already exists tcp://172.18.113.3:34863\n",
      "distributed.utils - ERROR - Worker already exists tcp://172.18.113.3:34099\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/anhoang/.conda/envs/dask-test/lib/python3.6/site-packages/distributed/utils.py\", line 649, in log_errors\n",
      "    yield\n",
      "  File \"/home/anhoang/.conda/envs/dask-test/lib/python3.6/site-packages/distributed/scheduler.py\", line 1281, in add_worker\n",
      "    raise ValueError(\"Worker already exists %s\" % address)\n",
      "ValueError: Worker already exists tcp://172.18.113.3:34099\n",
      "distributed.core - ERROR - Worker already exists tcp://172.18.113.3:34099\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/anhoang/.conda/envs/dask-test/lib/python3.6/site-packages/distributed/core.py\", line 346, in handle_comm\n",
      "    result = yield result\n",
      "  File \"/home/anhoang/.conda/envs/dask-test/lib/python3.6/site-packages/tornado/gen.py\", line 1133, in run\n",
      "    value = future.result()\n",
      "  File \"/home/anhoang/.conda/envs/dask-test/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/home/anhoang/.conda/envs/dask-test/lib/python3.6/site-packages/distributed/scheduler.py\", line 1281, in add_worker\n",
      "    raise ValueError(\"Worker already exists %s\" % address)\n",
      "ValueError: Worker already exists tcp://172.18.113.3:34099\n",
      "Worker tcp://172.18.113.4:42051 restart in Job 7063534. This can be due to memory issue.\n",
      "distributed.utils - ERROR - Worker already exists tcp://172.18.113.4:40669\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/anhoang/.conda/envs/dask-test/lib/python3.6/site-packages/distributed/utils.py\", line 649, in log_errors\n",
      "    yield\n",
      "  File \"/home/anhoang/.conda/envs/dask-test/lib/python3.6/site-packages/distributed/scheduler.py\", line 1281, in add_worker\n",
      "    raise ValueError(\"Worker already exists %s\" % address)\n",
      "ValueError: Worker already exists tcp://172.18.113.4:40669\n",
      "distributed.core - ERROR - Worker already exists tcp://172.18.113.4:40669\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/anhoang/.conda/envs/dask-test/lib/python3.6/site-packages/distributed/core.py\", line 346, in handle_comm\n",
      "    result = yield result\n",
      "  File \"/home/anhoang/.conda/envs/dask-test/lib/python3.6/site-packages/tornado/gen.py\", line 1133, in run\n",
      "    value = future.result()\n",
      "  File \"/home/anhoang/.conda/envs/dask-test/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/home/anhoang/.conda/envs/dask-test/lib/python3.6/site-packages/distributed/scheduler.py\", line 1281, in add_worker\n",
      "    raise ValueError(\"Worker already exists %s\" % address)\n",
      "ValueError: Worker already exists tcp://172.18.113.4:40669\n",
      "distributed.utils - ERROR - Worker already exists tcp://172.18.113.7:33979\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/anhoang/.conda/envs/dask-test/lib/python3.6/site-packages/distributed/utils.py\", line 649, in log_errors\n",
      "    yield\n",
      "  File \"/home/anhoang/.conda/envs/dask-test/lib/python3.6/site-packages/distributed/scheduler.py\", line 1281, in add_worker\n",
      "    raise ValueError(\"Worker already exists %s\" % address)\n",
      "ValueError: Worker already exists tcp://172.18.113.7:33979\n",
      "distributed.core - ERROR - Worker already exists tcp://172.18.113.7:33979\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/anhoang/.conda/envs/dask-test/lib/python3.6/site-packages/distributed/core.py\", line 346, in handle_comm\n",
      "    result = yield result\n",
      "  File \"/home/anhoang/.conda/envs/dask-test/lib/python3.6/site-packages/tornado/gen.py\", line 1133, in run\n",
      "    value = future.result()\n",
      "  File \"/home/anhoang/.conda/envs/dask-test/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/home/anhoang/.conda/envs/dask-test/lib/python3.6/site-packages/distributed/scheduler.py\", line 1281, in add_worker\n",
      "    raise ValueError(\"Worker already exists %s\" % address)\n",
      "ValueError: Worker already exists tcp://172.18.113.7:33979\n",
      "distributed.utils - ERROR - Worker already exists tcp://172.18.113.6:36279\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/anhoang/.conda/envs/dask-test/lib/python3.6/site-packages/distributed/utils.py\", line 649, in log_errors\n",
      "    yield\n",
      "  File \"/home/anhoang/.conda/envs/dask-test/lib/python3.6/site-packages/distributed/scheduler.py\", line 1281, in add_worker\n",
      "    raise ValueError(\"Worker already exists %s\" % address)\n",
      "ValueError: Worker already exists tcp://172.18.113.6:36279\n",
      "distributed.core - ERROR - Worker already exists tcp://172.18.113.6:36279\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/anhoang/.conda/envs/dask-test/lib/python3.6/site-packages/distributed/core.py\", line 346, in handle_comm\n",
      "    result = yield result\n",
      "  File \"/home/anhoang/.conda/envs/dask-test/lib/python3.6/site-packages/tornado/gen.py\", line 1133, in run\n",
      "    value = future.result()\n",
      "  File \"/home/anhoang/.conda/envs/dask-test/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/home/anhoang/.conda/envs/dask-test/lib/python3.6/site-packages/distributed/scheduler.py\", line 1281, in add_worker\n",
      "    raise ValueError(\"Worker already exists %s\" % address)\n",
      "ValueError: Worker already exists tcp://172.18.113.6:36279\n",
      "distributed.utils - ERROR - Worker already exists tcp://172.18.113.6:41639\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/anhoang/.conda/envs/dask-test/lib/python3.6/site-packages/distributed/utils.py\", line 649, in log_errors\n",
      "    yield\n",
      "  File \"/home/anhoang/.conda/envs/dask-test/lib/python3.6/site-packages/distributed/scheduler.py\", line 1281, in add_worker\n",
      "    raise ValueError(\"Worker already exists %s\" % address)\n",
      "ValueError: Worker already exists tcp://172.18.113.6:41639\n",
      "distributed.core - ERROR - Worker already exists tcp://172.18.113.6:41639\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/anhoang/.conda/envs/dask-test/lib/python3.6/site-packages/distributed/core.py\", line 346, in handle_comm\n",
      "    result = yield result\n",
      "  File \"/home/anhoang/.conda/envs/dask-test/lib/python3.6/site-packages/tornado/gen.py\", line 1133, in run\n",
      "    value = future.result()\n",
      "  File \"/home/anhoang/.conda/envs/dask-test/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/home/anhoang/.conda/envs/dask-test/lib/python3.6/site-packages/distributed/scheduler.py\", line 1281, in add_worker\n",
      "    raise ValueError(\"Worker already exists %s\" % address)\n",
      "ValueError: Worker already exists tcp://172.18.113.6:41639\n",
      "distributed.utils - ERROR - Worker already exists tcp://172.18.113.6:37741\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/anhoang/.conda/envs/dask-test/lib/python3.6/site-packages/distributed/utils.py\", line 649, in log_errors\n",
      "    yield\n",
      "  File \"/home/anhoang/.conda/envs/dask-test/lib/python3.6/site-packages/distributed/scheduler.py\", line 1281, in add_worker\n",
      "    raise ValueError(\"Worker already exists %s\" % address)\n",
      "ValueError: Worker already exists tcp://172.18.113.6:37741\n",
      "distributed.core - ERROR - Worker already exists tcp://172.18.113.6:37741\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/anhoang/.conda/envs/dask-test/lib/python3.6/site-packages/distributed/core.py\", line 346, in handle_comm\n",
      "    result = yield result\n",
      "  File \"/home/anhoang/.conda/envs/dask-test/lib/python3.6/site-packages/tornado/gen.py\", line 1133, in run\n",
      "    value = future.result()\n",
      "  File \"/home/anhoang/.conda/envs/dask-test/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/home/anhoang/.conda/envs/dask-test/lib/python3.6/site-packages/distributed/scheduler.py\", line 1281, in add_worker\n",
      "    raise ValueError(\"Worker already exists %s\" % address)\n",
      "ValueError: Worker already exists tcp://172.18.113.6:37741\n",
      "distributed.utils - ERROR - Worker already exists tcp://172.18.113.1:35033\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/anhoang/.conda/envs/dask-test/lib/python3.6/site-packages/distributed/utils.py\", line 649, in log_errors\n",
      "    yield\n",
      "  File \"/home/anhoang/.conda/envs/dask-test/lib/python3.6/site-packages/distributed/scheduler.py\", line 1281, in add_worker\n",
      "    raise ValueError(\"Worker already exists %s\" % address)\n",
      "ValueError: Worker already exists tcp://172.18.113.1:35033\n",
      "distributed.core - ERROR - Worker already exists tcp://172.18.113.1:35033\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/anhoang/.conda/envs/dask-test/lib/python3.6/site-packages/distributed/core.py\", line 346, in handle_comm\n",
      "    result = yield result\n",
      "  File \"/home/anhoang/.conda/envs/dask-test/lib/python3.6/site-packages/tornado/gen.py\", line 1133, in run\n",
      "    value = future.result()\n",
      "  File \"/home/anhoang/.conda/envs/dask-test/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/home/anhoang/.conda/envs/dask-test/lib/python3.6/site-packages/distributed/scheduler.py\", line 1281, in add_worker\n",
      "    raise ValueError(\"Worker already exists %s\" % address)\n",
      "ValueError: Worker already exists tcp://172.18.113.1:35033\n",
      "distributed.utils - ERROR - Worker already exists tcp://172.18.113.1:41223\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/anhoang/.conda/envs/dask-test/lib/python3.6/site-packages/distributed/utils.py\", line 649, in log_errors\n",
      "    yield\n",
      "  File \"/home/anhoang/.conda/envs/dask-test/lib/python3.6/site-packages/distributed/scheduler.py\", line 1281, in add_worker\n",
      "    raise ValueError(\"Worker already exists %s\" % address)\n",
      "ValueError: Worker already exists tcp://172.18.113.1:41223\n",
      "distributed.core - ERROR - Worker already exists tcp://172.18.113.1:41223\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/anhoang/.conda/envs/dask-test/lib/python3.6/site-packages/distributed/core.py\", line 346, in handle_comm\n",
      "    result = yield result\n",
      "  File \"/home/anhoang/.conda/envs/dask-test/lib/python3.6/site-packages/tornado/gen.py\", line 1133, in run\n",
      "    value = future.result()\n",
      "  File \"/home/anhoang/.conda/envs/dask-test/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/home/anhoang/.conda/envs/dask-test/lib/python3.6/site-packages/distributed/scheduler.py\", line 1281, in add_worker\n",
      "    raise ValueError(\"Worker already exists %s\" % address)\n",
      "ValueError: Worker already exists tcp://172.18.113.1:41223\n",
      "distributed.utils - ERROR - Worker already exists tcp://172.18.113.1:42543\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/anhoang/.conda/envs/dask-test/lib/python3.6/site-packages/distributed/utils.py\", line 649, in log_errors\n",
      "    yield\n",
      "  File \"/home/anhoang/.conda/envs/dask-test/lib/python3.6/site-packages/distributed/scheduler.py\", line 1281, in add_worker\n",
      "    raise ValueError(\"Worker already exists %s\" % address)\n",
      "ValueError: Worker already exists tcp://172.18.113.1:42543\n",
      "distributed.core - ERROR - Worker already exists tcp://172.18.113.1:42543\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/anhoang/.conda/envs/dask-test/lib/python3.6/site-packages/distributed/core.py\", line 346, in handle_comm\n",
      "    result = yield result\n",
      "  File \"/home/anhoang/.conda/envs/dask-test/lib/python3.6/site-packages/tornado/gen.py\", line 1133, in run\n",
      "    value = future.result()\n",
      "  File \"/home/anhoang/.conda/envs/dask-test/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/home/anhoang/.conda/envs/dask-test/lib/python3.6/site-packages/distributed/scheduler.py\", line 1281, in add_worker\n",
      "    raise ValueError(\"Worker already exists %s\" % address)\n",
      "ValueError: Worker already exists tcp://172.18.113.1:42543\n",
      "distributed.utils - ERROR - Worker already exists tcp://172.18.113.4:42051\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/anhoang/.conda/envs/dask-test/lib/python3.6/site-packages/distributed/utils.py\", line 649, in log_errors\n",
      "    yield\n",
      "  File \"/home/anhoang/.conda/envs/dask-test/lib/python3.6/site-packages/distributed/scheduler.py\", line 1281, in add_worker\n",
      "    raise ValueError(\"Worker already exists %s\" % address)\n",
      "ValueError: Worker already exists tcp://172.18.113.4:42051\n",
      "distributed.core - ERROR - Worker already exists tcp://172.18.113.4:42051\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/anhoang/.conda/envs/dask-test/lib/python3.6/site-packages/distributed/core.py\", line 346, in handle_comm\n",
      "    result = yield result\n",
      "  File \"/home/anhoang/.conda/envs/dask-test/lib/python3.6/site-packages/tornado/gen.py\", line 1133, in run\n",
      "    value = future.result()\n",
      "  File \"/home/anhoang/.conda/envs/dask-test/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/home/anhoang/.conda/envs/dask-test/lib/python3.6/site-packages/distributed/scheduler.py\", line 1281, in add_worker\n",
      "    raise ValueError(\"Worker already exists %s\" % address)\n",
      "ValueError: Worker already exists tcp://172.18.113.4:42051\n",
      "Worker tcp://172.18.113.10:46449 restart in Job 7063595. This can be due to memory issue.\n",
      "Worker tcp://172.18.113.8:45653 restart in Job 7065481. This can be due to memory issue.\n",
      "distributed.utils - ERROR - Worker already exists tcp://172.18.113.8:45653\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/anhoang/.conda/envs/dask-test/lib/python3.6/site-packages/distributed/utils.py\", line 649, in log_errors\n",
      "    yield\n",
      "  File \"/home/anhoang/.conda/envs/dask-test/lib/python3.6/site-packages/distributed/scheduler.py\", line 1281, in add_worker\n",
      "    raise ValueError(\"Worker already exists %s\" % address)\n",
      "ValueError: Worker already exists tcp://172.18.113.8:45653\n",
      "distributed.core - ERROR - Worker already exists tcp://172.18.113.8:45653\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/anhoang/.conda/envs/dask-test/lib/python3.6/site-packages/distributed/core.py\", line 346, in handle_comm\n",
      "    result = yield result\n",
      "  File \"/home/anhoang/.conda/envs/dask-test/lib/python3.6/site-packages/tornado/gen.py\", line 1133, in run\n",
      "    value = future.result()\n",
      "  File \"/home/anhoang/.conda/envs/dask-test/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/home/anhoang/.conda/envs/dask-test/lib/python3.6/site-packages/distributed/scheduler.py\", line 1281, in add_worker\n",
      "    raise ValueError(\"Worker already exists %s\" % address)\n",
      "ValueError: Worker already exists tcp://172.18.113.8:45653\n",
      "Worker tcp://172.18.113.8:38225 restart in Job 7063517. This can be due to memory issue.\n",
      "Worker tcp://172.18.113.10:36457 restart in Job 7063564. This can be due to memory issue.\n"
     ]
    }
   ],
   "source": [
    "tp.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tp.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Attempt 2: using 4 cores/worker, 100 workers, increased memory to 30GB each, n_jobs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from dask_jobqueue import LSFCluster\n",
    "from dask.distributed import Client, progress\n",
    "from timeit import default_timer as timer\n",
    "import dask.bag as db\n",
    "import dask.dataframe as dd\n",
    "import gc\n",
    "try:\n",
    "    gc.enable()\n",
    "    del cluster\n",
    "    del client\n",
    "    gc.collect(cluster)\n",
    "    gc.collect(client)\n",
    "except:\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#!/bin/bash\n",
      "\n",
      "#BSUB -J dask-worker\n",
      "#BSUB -q corradin_long\n",
      "#BSUB -n 4\n",
      "#BSUB -R \"span[hosts=1]\"\n",
      "#BSUB -M 15000\n",
      "#BSUB -W 100000:00\n",
      "#BSUB -o /dev/null\n",
      "#BSUB -g /dask-workers\n",
      "#BSUB -e error_log_worker\n",
      "JOB_ID=${LSB_JOBID%.*}\n",
      "\n",
      "\n",
      "\n",
      "/home/anhoang/.conda/envs/dask-test/bin/python -m distributed.cli.dask_worker tcp://172.18.10.1:36181 --nthreads 4 --memory-limit 15.00GB --name dask-worker--${JOB_ID}-- --death-timeout 600\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cluster = LSFCluster(queue='corradin_long',\n",
    "                     cores= 4,\n",
    "                     #ncpus=2,\n",
    "                     walltime='100000:00',\n",
    "                     memory='15GB',\n",
    "                     death_timeout=600,\n",
    "                     job_extra=['-o /dev/null', '-g /dask-workers', '-e error_log_worker' ]#, '']\n",
    "                     )\n",
    "cluster.adapt(minimum= 100, maximum=100)\n",
    "#cluster.scale(250)\n",
    "print(cluster.job_script())\n",
    "cluster.dashboard_link\n",
    "client = Client(cluster)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale up: Increase the TPOT parameters like population_size, generations\n",
    "tp = TPOTRegressor(\n",
    "#     generations=2,\n",
    "    population_size=1000,\n",
    "#     cv=2,\n",
    "    n_jobs=50,\n",
    "    warm_start=True,\n",
    "    random_state=0,\n",
    "    verbosity=3,\n",
    "    periodic_checkpoint_folder = \"./tpot_checkpoints\",\n",
    "    memory = \"./memory\",\n",
    "    use_dask=True,\n",
    "    #config_dict = 'TPOT sparse'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"border: 2px solid white;\">\n",
       "<tr>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3>Client</h3>\n",
       "<ul>\n",
       "  <li><b>Scheduler: </b>tcp://172.18.10.1:36181\n",
       "  <li><b>Dashboard: </b><a href='http://172.18.10.1:8787/status' target='_blank'>http://172.18.10.1:8787/status</a>\n",
       "</ul>\n",
       "</td>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3>Cluster</h3>\n",
       "<ul>\n",
       "  <li><b>Workers: </b>100</li>\n",
       "  <li><b>Cores: </b>400</li>\n",
       "  <li><b>Memory: </b>1.50 TB</li>\n",
       "</ul>\n",
       "</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Client: scheduler='tcp://172.18.10.1:36181' processes=100 cores=400>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#executed this cell for a few times until all workers arrived\n",
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29 operators have been imported by TPOT.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5d8a15d5a9c48feb95eb24960b55ebd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Optimization Progress', max=101000, style=ProgressStyle(descr…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Worker tcp://172.18.113.9:35275 restart in Job 7066784. This can be due to memory issue.\n",
      "Worker tcp://172.18.113.9:33279 restart in Job 7066773. This can be due to memory issue.\n",
      "Worker tcp://172.18.113.5:40349 restart in Job 7066824. This can be due to memory issue.\n",
      "Worker tcp://172.18.113.4:41579 restart in Job 7066806. This can be due to memory issue.\n",
      "Worker tcp://172.18.113.3:44587 restart in Job 7066847. This can be due to memory issue.\n",
      "Worker tcp://172.18.113.11:37609 restart in Job 7066800. This can be due to memory issue.\n",
      "Worker tcp://172.18.113.8:42559 restart in Job 7066752. This can be due to memory issue.\n",
      "Worker tcp://172.18.113.1:42815 restart in Job 7066791. This can be due to memory issue.\n",
      "Worker tcp://172.18.113.9:40021 restart in Job 7066808. This can be due to memory issue.\n",
      "Worker tcp://172.18.113.9:34691 restart in Job 7066831. This can be due to memory issue.\n",
      "Worker tcp://172.18.113.9:33993 restart in Job 7066750. This can be due to memory issue.\n",
      "Worker tcp://172.18.113.9:34691 restart in Job 7066831. This can be due to memory issue.\n",
      "Worker tcp://172.18.113.9:33279 restart in Job 7066773. This can be due to memory issue.\n",
      "distributed.utils - ERROR - Worker already exists tcp://172.18.113.9:33279\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/anhoang/.conda/envs/dask-test/lib/python3.6/site-packages/distributed/utils.py\", line 649, in log_errors\n",
      "    yield\n",
      "  File \"/home/anhoang/.conda/envs/dask-test/lib/python3.6/site-packages/distributed/scheduler.py\", line 1281, in add_worker\n",
      "    raise ValueError(\"Worker already exists %s\" % address)\n",
      "ValueError: Worker already exists tcp://172.18.113.9:33279\n",
      "distributed.core - ERROR - Worker already exists tcp://172.18.113.9:33279\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/anhoang/.conda/envs/dask-test/lib/python3.6/site-packages/distributed/core.py\", line 346, in handle_comm\n",
      "    result = yield result\n",
      "  File \"/home/anhoang/.conda/envs/dask-test/lib/python3.6/site-packages/tornado/gen.py\", line 1133, in run\n",
      "    value = future.result()\n",
      "  File \"/home/anhoang/.conda/envs/dask-test/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/home/anhoang/.conda/envs/dask-test/lib/python3.6/site-packages/distributed/scheduler.py\", line 1281, in add_worker\n",
      "    raise ValueError(\"Worker already exists %s\" % address)\n",
      "ValueError: Worker already exists tcp://172.18.113.9:33279\n",
      "Worker tcp://172.18.113.11:35635 restart in Job 7066760. This can be due to memory issue.\n",
      "Worker tcp://172.18.113.9:34691 restart in Job 7066831. This can be due to memory issue.\n",
      "Worker tcp://172.18.113.5:38021 restart in Job 7066774. This can be due to memory issue.\n",
      "Worker tcp://172.18.113.5:42419 restart in Job 7066813. This can be due to memory issue.\n",
      "Worker tcp://172.18.113.4:33431 restart in Job 7066835. This can be due to memory issue.\n",
      "Worker tcp://172.18.113.4:43837 restart in Job 7066788. This can be due to memory issue.\n",
      "Worker tcp://172.18.113.4:38081 restart in Job 7066798. This can be due to memory issue.\n",
      "Worker tcp://172.18.113.3:34597 restart in Job 7066836. This can be due to memory issue.\n",
      "Worker tcp://172.18.113.3:44587 restart in Job 7066847. This can be due to memory issue.\n",
      "Worker tcp://172.18.113.1:44189 restart in Job 7066770. This can be due to memory issue.\n",
      "Worker tcp://172.18.113.1:42815 restart in Job 7066791. This can be due to memory issue.\n",
      "distributed.utils - ERROR - Worker already exists tcp://172.18.113.1:42815\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/anhoang/.conda/envs/dask-test/lib/python3.6/site-packages/distributed/utils.py\", line 649, in log_errors\n",
      "    yield\n",
      "  File \"/home/anhoang/.conda/envs/dask-test/lib/python3.6/site-packages/distributed/scheduler.py\", line 1281, in add_worker\n",
      "    raise ValueError(\"Worker already exists %s\" % address)\n",
      "ValueError: Worker already exists tcp://172.18.113.1:42815\n",
      "distributed.core - ERROR - Worker already exists tcp://172.18.113.1:42815\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/anhoang/.conda/envs/dask-test/lib/python3.6/site-packages/distributed/core.py\", line 346, in handle_comm\n",
      "    result = yield result\n",
      "  File \"/home/anhoang/.conda/envs/dask-test/lib/python3.6/site-packages/tornado/gen.py\", line 1133, in run\n",
      "    value = future.result()\n",
      "  File \"/home/anhoang/.conda/envs/dask-test/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/home/anhoang/.conda/envs/dask-test/lib/python3.6/site-packages/distributed/scheduler.py\", line 1281, in add_worker\n",
      "    raise ValueError(\"Worker already exists %s\" % address)\n",
      "ValueError: Worker already exists tcp://172.18.113.1:42815\n",
      "Worker tcp://172.18.113.1:42815 restart in Job 7066791. This can be due to memory issue.\n",
      "Worker tcp://172.18.113.10:35975 restart in Job 7066766. This can be due to memory issue.\n",
      "Worker tcp://172.18.113.2:43019 restart in Job 7066769. This can be due to memory issue.\n",
      "Worker tcp://172.18.113.2:33121 restart in Job 7066833. This can be due to memory issue.\n",
      "Worker tcp://172.18.113.2:36373 restart in Job 7066758. This can be due to memory issue.\n",
      "Worker tcp://172.18.113.2:45319 restart in Job 7066790. This can be due to memory issue.\n",
      "distributed.core - ERROR - 'tcp://172.18.113.2:45319'\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/anhoang/.conda/envs/dask-test/lib/python3.6/site-packages/distributed/core.py\", line 400, in handle_stream\n",
      "    handler(**merge(extra, msg))\n",
      "  File \"/home/anhoang/.conda/envs/dask-test/lib/python3.6/site-packages/distributed/scheduler.py\", line 2134, in handle_release_data\n",
      "    ws = self.workers[worker]\n",
      "KeyError: 'tcp://172.18.113.2:45319'\n",
      "distributed.utils - ERROR - 'tcp://172.18.113.2:45319'\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/anhoang/.conda/envs/dask-test/lib/python3.6/site-packages/distributed/utils.py\", line 649, in log_errors\n",
      "    yield\n",
      "  File \"/home/anhoang/.conda/envs/dask-test/lib/python3.6/site-packages/distributed/scheduler.py\", line 1359, in add_worker\n",
      "    yield self.handle_worker(comm=comm, worker=address)\n",
      "  File \"/home/anhoang/.conda/envs/dask-test/lib/python3.6/site-packages/tornado/gen.py\", line 1133, in run\n",
      "    value = future.result()\n",
      "  File \"/home/anhoang/.conda/envs/dask-test/lib/python3.6/site-packages/tornado/gen.py\", line 1141, in run\n",
      "    yielded = self.gen.throw(*exc_info)\n",
      "  File \"/home/anhoang/.conda/envs/dask-test/lib/python3.6/site-packages/distributed/scheduler.py\", line 2223, in handle_worker\n",
      "    yield self.handle_stream(comm=comm, extra={'worker': worker})\n",
      "  File \"/home/anhoang/.conda/envs/dask-test/lib/python3.6/site-packages/tornado/gen.py\", line 1133, in run\n",
      "    value = future.result()\n",
      "  File \"/home/anhoang/.conda/envs/dask-test/lib/python3.6/site-packages/tornado/gen.py\", line 1147, in run\n",
      "    yielded = self.gen.send(value)\n",
      "  File \"/home/anhoang/.conda/envs/dask-test/lib/python3.6/site-packages/distributed/core.py\", line 400, in handle_stream\n",
      "    handler(**merge(extra, msg))\n",
      "  File \"/home/anhoang/.conda/envs/dask-test/lib/python3.6/site-packages/distributed/scheduler.py\", line 2134, in handle_release_data\n",
      "    ws = self.workers[worker]\n",
      "KeyError: 'tcp://172.18.113.2:45319'\n",
      "distributed.core - ERROR - 'tcp://172.18.113.2:45319'\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/anhoang/.conda/envs/dask-test/lib/python3.6/site-packages/distributed/core.py\", line 346, in handle_comm\n",
      "    result = yield result\n",
      "  File \"/home/anhoang/.conda/envs/dask-test/lib/python3.6/site-packages/tornado/gen.py\", line 1133, in run\n",
      "    value = future.result()\n",
      "  File \"/home/anhoang/.conda/envs/dask-test/lib/python3.6/site-packages/tornado/gen.py\", line 1141, in run\n",
      "    yielded = self.gen.throw(*exc_info)\n",
      "  File \"/home/anhoang/.conda/envs/dask-test/lib/python3.6/site-packages/distributed/scheduler.py\", line 1359, in add_worker\n",
      "    yield self.handle_worker(comm=comm, worker=address)\n",
      "  File \"/home/anhoang/.conda/envs/dask-test/lib/python3.6/site-packages/tornado/gen.py\", line 1133, in run\n",
      "    value = future.result()\n",
      "  File \"/home/anhoang/.conda/envs/dask-test/lib/python3.6/site-packages/tornado/gen.py\", line 1141, in run\n",
      "    yielded = self.gen.throw(*exc_info)\n",
      "  File \"/home/anhoang/.conda/envs/dask-test/lib/python3.6/site-packages/distributed/scheduler.py\", line 2223, in handle_worker\n",
      "    yield self.handle_stream(comm=comm, extra={'worker': worker})\n",
      "  File \"/home/anhoang/.conda/envs/dask-test/lib/python3.6/site-packages/tornado/gen.py\", line 1133, in run\n",
      "    value = future.result()\n",
      "  File \"/home/anhoang/.conda/envs/dask-test/lib/python3.6/site-packages/tornado/gen.py\", line 1147, in run\n",
      "    yielded = self.gen.send(value)\n",
      "  File \"/home/anhoang/.conda/envs/dask-test/lib/python3.6/site-packages/distributed/core.py\", line 400, in handle_stream\n",
      "    handler(**merge(extra, msg))\n",
      "  File \"/home/anhoang/.conda/envs/dask-test/lib/python3.6/site-packages/distributed/scheduler.py\", line 2134, in handle_release_data\n",
      "    ws = self.workers[worker]\n",
      "KeyError: 'tcp://172.18.113.2:45319'\n",
      "Worker tcp://172.18.113.8:35145 restart in Job 7066772. This can be due to memory issue.\n",
      "Worker tcp://172.18.113.6:34635 restart in Job 7066811. This can be due to memory issue.\n",
      "Worker tcp://172.18.113.8:44871 restart in Job 7066783. This can be due to memory issue.\n",
      "Worker tcp://172.18.113.3:46693 restart in Job 7066816. This can be due to memory issue.\n",
      "Worker tcp://172.18.113.3:46693 restart in Job 7066816. This can be due to memory issue.\n",
      "distributed.utils - ERROR - Worker already exists tcp://172.18.113.3:46693\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/anhoang/.conda/envs/dask-test/lib/python3.6/site-packages/distributed/utils.py\", line 649, in log_errors\n",
      "    yield\n",
      "  File \"/home/anhoang/.conda/envs/dask-test/lib/python3.6/site-packages/distributed/scheduler.py\", line 1281, in add_worker\n",
      "    raise ValueError(\"Worker already exists %s\" % address)\n",
      "ValueError: Worker already exists tcp://172.18.113.3:46693\n",
      "distributed.core - ERROR - Worker already exists tcp://172.18.113.3:46693\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/anhoang/.conda/envs/dask-test/lib/python3.6/site-packages/distributed/core.py\", line 346, in handle_comm\n",
      "    result = yield result\n",
      "  File \"/home/anhoang/.conda/envs/dask-test/lib/python3.6/site-packages/tornado/gen.py\", line 1133, in run\n",
      "    value = future.result()\n",
      "  File \"/home/anhoang/.conda/envs/dask-test/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/home/anhoang/.conda/envs/dask-test/lib/python3.6/site-packages/distributed/scheduler.py\", line 1281, in add_worker\n",
      "    raise ValueError(\"Worker already exists %s\" % address)\n",
      "ValueError: Worker already exists tcp://172.18.113.3:46693\n",
      "Worker tcp://172.18.113.5:40159 restart in Job 7066774. This can be due to memory issue.\n",
      "Worker tcp://172.18.113.10:37247 restart in Job 7066818. This can be due to memory issue.\n",
      "distributed.core - ERROR - 'tcp://172.18.113.8:38085'\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/anhoang/.conda/envs/dask-test/lib/python3.6/site-packages/distributed/core.py\", line 400, in handle_stream\n",
      "    handler(**merge(extra, msg))\n",
      "  File \"/home/anhoang/.conda/envs/dask-test/lib/python3.6/site-packages/distributed/scheduler.py\", line 2134, in handle_release_data\n",
      "    ws = self.workers[worker]\n",
      "KeyError: 'tcp://172.18.113.8:38085'\n",
      "distributed.utils - ERROR - 'tcp://172.18.113.8:38085'\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/anhoang/.conda/envs/dask-test/lib/python3.6/site-packages/distributed/utils.py\", line 649, in log_errors\n",
      "    yield\n",
      "  File \"/home/anhoang/.conda/envs/dask-test/lib/python3.6/site-packages/distributed/scheduler.py\", line 1359, in add_worker\n",
      "    yield self.handle_worker(comm=comm, worker=address)\n",
      "  File \"/home/anhoang/.conda/envs/dask-test/lib/python3.6/site-packages/tornado/gen.py\", line 1133, in run\n",
      "    value = future.result()\n",
      "  File \"/home/anhoang/.conda/envs/dask-test/lib/python3.6/site-packages/tornado/gen.py\", line 1141, in run\n",
      "    yielded = self.gen.throw(*exc_info)\n",
      "  File \"/home/anhoang/.conda/envs/dask-test/lib/python3.6/site-packages/distributed/scheduler.py\", line 2223, in handle_worker\n",
      "    yield self.handle_stream(comm=comm, extra={'worker': worker})\n",
      "  File \"/home/anhoang/.conda/envs/dask-test/lib/python3.6/site-packages/tornado/gen.py\", line 1133, in run\n",
      "    value = future.result()\n",
      "  File \"/home/anhoang/.conda/envs/dask-test/lib/python3.6/site-packages/tornado/gen.py\", line 1147, in run\n",
      "    yielded = self.gen.send(value)\n",
      "  File \"/home/anhoang/.conda/envs/dask-test/lib/python3.6/site-packages/distributed/core.py\", line 400, in handle_stream\n",
      "    handler(**merge(extra, msg))\n",
      "  File \"/home/anhoang/.conda/envs/dask-test/lib/python3.6/site-packages/distributed/scheduler.py\", line 2134, in handle_release_data\n",
      "    ws = self.workers[worker]\n",
      "KeyError: 'tcp://172.18.113.8:38085'\n",
      "distributed.core - ERROR - 'tcp://172.18.113.8:38085'\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/anhoang/.conda/envs/dask-test/lib/python3.6/site-packages/distributed/core.py\", line 346, in handle_comm\n",
      "    result = yield result\n",
      "  File \"/home/anhoang/.conda/envs/dask-test/lib/python3.6/site-packages/tornado/gen.py\", line 1133, in run\n",
      "    value = future.result()\n",
      "  File \"/home/anhoang/.conda/envs/dask-test/lib/python3.6/site-packages/tornado/gen.py\", line 1141, in run\n",
      "    yielded = self.gen.throw(*exc_info)\n",
      "  File \"/home/anhoang/.conda/envs/dask-test/lib/python3.6/site-packages/distributed/scheduler.py\", line 1359, in add_worker\n",
      "    yield self.handle_worker(comm=comm, worker=address)\n",
      "  File \"/home/anhoang/.conda/envs/dask-test/lib/python3.6/site-packages/tornado/gen.py\", line 1133, in run\n",
      "    value = future.result()\n",
      "  File \"/home/anhoang/.conda/envs/dask-test/lib/python3.6/site-packages/tornado/gen.py\", line 1141, in run\n",
      "    yielded = self.gen.throw(*exc_info)\n",
      "  File \"/home/anhoang/.conda/envs/dask-test/lib/python3.6/site-packages/distributed/scheduler.py\", line 2223, in handle_worker\n",
      "    yield self.handle_stream(comm=comm, extra={'worker': worker})\n",
      "  File \"/home/anhoang/.conda/envs/dask-test/lib/python3.6/site-packages/tornado/gen.py\", line 1133, in run\n",
      "    value = future.result()\n",
      "  File \"/home/anhoang/.conda/envs/dask-test/lib/python3.6/site-packages/tornado/gen.py\", line 1147, in run\n",
      "    yielded = self.gen.send(value)\n",
      "  File \"/home/anhoang/.conda/envs/dask-test/lib/python3.6/site-packages/distributed/core.py\", line 400, in handle_stream\n",
      "    handler(**merge(extra, msg))\n",
      "  File \"/home/anhoang/.conda/envs/dask-test/lib/python3.6/site-packages/distributed/scheduler.py\", line 2134, in handle_release_data\n",
      "    ws = self.workers[worker]\n",
      "KeyError: 'tcp://172.18.113.8:38085'\n",
      "Worker tcp://172.18.113.10:44925 restart in Job 7066840. This can be due to memory issue.\n",
      "Worker tcp://172.18.113.6:46209 restart in Job 7066751. This can be due to memory issue.\n",
      "Worker tcp://172.18.113.1:43659 restart in Job 7066837. This can be due to memory issue.\n",
      "Worker tcp://172.18.113.1:42737 restart in Job 7066780. This can be due to memory issue.\n",
      "Worker tcp://172.18.113.7:39675 restart in Job 7066863. This can be due to memory issue.\n",
      "distributed.utils - ERROR - Worker already exists tcp://172.18.113.7:39675\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/anhoang/.conda/envs/dask-test/lib/python3.6/site-packages/distributed/utils.py\", line 649, in log_errors\n",
      "    yield\n",
      "  File \"/home/anhoang/.conda/envs/dask-test/lib/python3.6/site-packages/distributed/scheduler.py\", line 1281, in add_worker\n",
      "    raise ValueError(\"Worker already exists %s\" % address)\n",
      "ValueError: Worker already exists tcp://172.18.113.7:39675\n",
      "distributed.core - ERROR - Worker already exists tcp://172.18.113.7:39675\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/anhoang/.conda/envs/dask-test/lib/python3.6/site-packages/distributed/core.py\", line 346, in handle_comm\n",
      "    result = yield result\n",
      "  File \"/home/anhoang/.conda/envs/dask-test/lib/python3.6/site-packages/tornado/gen.py\", line 1133, in run\n",
      "    value = future.result()\n",
      "  File \"/home/anhoang/.conda/envs/dask-test/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/home/anhoang/.conda/envs/dask-test/lib/python3.6/site-packages/distributed/scheduler.py\", line 1281, in add_worker\n",
      "    raise ValueError(\"Worker already exists %s\" % address)\n",
      "ValueError: Worker already exists tcp://172.18.113.7:39675\n",
      "Worker tcp://172.18.113.8:45053 restart in Job 7066772. This can be due to memory issue.\n",
      "distributed.core - ERROR - 'tcp://172.18.113.5:37989'\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/anhoang/.conda/envs/dask-test/lib/python3.6/site-packages/distributed/core.py\", line 400, in handle_stream\n",
      "    handler(**merge(extra, msg))\n",
      "  File \"/home/anhoang/.conda/envs/dask-test/lib/python3.6/site-packages/distributed/scheduler.py\", line 2134, in handle_release_data\n",
      "    ws = self.workers[worker]\n",
      "KeyError: 'tcp://172.18.113.5:37989'\n",
      "distributed.utils - ERROR - 'tcp://172.18.113.5:37989'\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/anhoang/.conda/envs/dask-test/lib/python3.6/site-packages/distributed/utils.py\", line 649, in log_errors\n",
      "    yield\n",
      "  File \"/home/anhoang/.conda/envs/dask-test/lib/python3.6/site-packages/distributed/scheduler.py\", line 1359, in add_worker\n",
      "    yield self.handle_worker(comm=comm, worker=address)\n",
      "  File \"/home/anhoang/.conda/envs/dask-test/lib/python3.6/site-packages/tornado/gen.py\", line 1133, in run\n",
      "    value = future.result()\n",
      "  File \"/home/anhoang/.conda/envs/dask-test/lib/python3.6/site-packages/tornado/gen.py\", line 1141, in run\n",
      "    yielded = self.gen.throw(*exc_info)\n",
      "  File \"/home/anhoang/.conda/envs/dask-test/lib/python3.6/site-packages/distributed/scheduler.py\", line 2223, in handle_worker\n",
      "    yield self.handle_stream(comm=comm, extra={'worker': worker})\n",
      "  File \"/home/anhoang/.conda/envs/dask-test/lib/python3.6/site-packages/tornado/gen.py\", line 1133, in run\n",
      "    value = future.result()\n",
      "  File \"/home/anhoang/.conda/envs/dask-test/lib/python3.6/site-packages/tornado/gen.py\", line 1147, in run\n",
      "    yielded = self.gen.send(value)\n",
      "  File \"/home/anhoang/.conda/envs/dask-test/lib/python3.6/site-packages/distributed/core.py\", line 400, in handle_stream\n",
      "    handler(**merge(extra, msg))\n",
      "  File \"/home/anhoang/.conda/envs/dask-test/lib/python3.6/site-packages/distributed/scheduler.py\", line 2134, in handle_release_data\n",
      "    ws = self.workers[worker]\n",
      "KeyError: 'tcp://172.18.113.5:37989'\n",
      "distributed.core - ERROR - 'tcp://172.18.113.5:37989'\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/anhoang/.conda/envs/dask-test/lib/python3.6/site-packages/distributed/core.py\", line 346, in handle_comm\n",
      "    result = yield result\n",
      "  File \"/home/anhoang/.conda/envs/dask-test/lib/python3.6/site-packages/tornado/gen.py\", line 1133, in run\n",
      "    value = future.result()\n",
      "  File \"/home/anhoang/.conda/envs/dask-test/lib/python3.6/site-packages/tornado/gen.py\", line 1141, in run\n",
      "    yielded = self.gen.throw(*exc_info)\n",
      "  File \"/home/anhoang/.conda/envs/dask-test/lib/python3.6/site-packages/distributed/scheduler.py\", line 1359, in add_worker\n",
      "    yield self.handle_worker(comm=comm, worker=address)\n",
      "  File \"/home/anhoang/.conda/envs/dask-test/lib/python3.6/site-packages/tornado/gen.py\", line 1133, in run\n",
      "    value = future.result()\n",
      "  File \"/home/anhoang/.conda/envs/dask-test/lib/python3.6/site-packages/tornado/gen.py\", line 1141, in run\n",
      "    yielded = self.gen.throw(*exc_info)\n",
      "  File \"/home/anhoang/.conda/envs/dask-test/lib/python3.6/site-packages/distributed/scheduler.py\", line 2223, in handle_worker\n",
      "    yield self.handle_stream(comm=comm, extra={'worker': worker})\n",
      "  File \"/home/anhoang/.conda/envs/dask-test/lib/python3.6/site-packages/tornado/gen.py\", line 1133, in run\n",
      "    value = future.result()\n",
      "  File \"/home/anhoang/.conda/envs/dask-test/lib/python3.6/site-packages/tornado/gen.py\", line 1147, in run\n",
      "    yielded = self.gen.send(value)\n",
      "  File \"/home/anhoang/.conda/envs/dask-test/lib/python3.6/site-packages/distributed/core.py\", line 400, in handle_stream\n",
      "    handler(**merge(extra, msg))\n",
      "  File \"/home/anhoang/.conda/envs/dask-test/lib/python3.6/site-packages/distributed/scheduler.py\", line 2134, in handle_release_data\n",
      "    ws = self.workers[worker]\n",
      "KeyError: 'tcp://172.18.113.5:37989'\n",
      "Worker tcp://172.18.113.10:40749 restart in Job 7066801. This can be due to memory issue.\n",
      "Worker tcp://172.18.113.2:42661 restart in Job 7066769. This can be due to memory issue.\n",
      "Worker tcp://172.18.113.4:43249 restart in Job 7066788. This can be due to memory issue.\n",
      "distributed.core - ERROR - 'tcp://172.18.113.6:37171'\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/anhoang/.conda/envs/dask-test/lib/python3.6/site-packages/distributed/core.py\", line 400, in handle_stream\n",
      "    handler(**merge(extra, msg))\n",
      "  File \"/home/anhoang/.conda/envs/dask-test/lib/python3.6/site-packages/distributed/scheduler.py\", line 2134, in handle_release_data\n",
      "    ws = self.workers[worker]\n",
      "KeyError: 'tcp://172.18.113.6:37171'\n",
      "distributed.utils - ERROR - 'tcp://172.18.113.6:37171'\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/anhoang/.conda/envs/dask-test/lib/python3.6/site-packages/distributed/utils.py\", line 649, in log_errors\n",
      "    yield\n",
      "  File \"/home/anhoang/.conda/envs/dask-test/lib/python3.6/site-packages/distributed/scheduler.py\", line 1359, in add_worker\n",
      "    yield self.handle_worker(comm=comm, worker=address)\n",
      "  File \"/home/anhoang/.conda/envs/dask-test/lib/python3.6/site-packages/tornado/gen.py\", line 1133, in run\n",
      "    value = future.result()\n",
      "  File \"/home/anhoang/.conda/envs/dask-test/lib/python3.6/site-packages/tornado/gen.py\", line 1141, in run\n",
      "    yielded = self.gen.throw(*exc_info)\n",
      "  File \"/home/anhoang/.conda/envs/dask-test/lib/python3.6/site-packages/distributed/scheduler.py\", line 2223, in handle_worker\n",
      "    yield self.handle_stream(comm=comm, extra={'worker': worker})\n",
      "  File \"/home/anhoang/.conda/envs/dask-test/lib/python3.6/site-packages/tornado/gen.py\", line 1133, in run\n",
      "    value = future.result()\n",
      "  File \"/home/anhoang/.conda/envs/dask-test/lib/python3.6/site-packages/tornado/gen.py\", line 1147, in run\n",
      "    yielded = self.gen.send(value)\n",
      "  File \"/home/anhoang/.conda/envs/dask-test/lib/python3.6/site-packages/distributed/core.py\", line 400, in handle_stream\n",
      "    handler(**merge(extra, msg))\n",
      "  File \"/home/anhoang/.conda/envs/dask-test/lib/python3.6/site-packages/distributed/scheduler.py\", line 2134, in handle_release_data\n",
      "    ws = self.workers[worker]\n",
      "KeyError: 'tcp://172.18.113.6:37171'\n",
      "distributed.core - ERROR - 'tcp://172.18.113.6:37171'\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/anhoang/.conda/envs/dask-test/lib/python3.6/site-packages/distributed/core.py\", line 346, in handle_comm\n",
      "    result = yield result\n",
      "  File \"/home/anhoang/.conda/envs/dask-test/lib/python3.6/site-packages/tornado/gen.py\", line 1133, in run\n",
      "    value = future.result()\n",
      "  File \"/home/anhoang/.conda/envs/dask-test/lib/python3.6/site-packages/tornado/gen.py\", line 1141, in run\n",
      "    yielded = self.gen.throw(*exc_info)\n",
      "  File \"/home/anhoang/.conda/envs/dask-test/lib/python3.6/site-packages/distributed/scheduler.py\", line 1359, in add_worker\n",
      "    yield self.handle_worker(comm=comm, worker=address)\n",
      "  File \"/home/anhoang/.conda/envs/dask-test/lib/python3.6/site-packages/tornado/gen.py\", line 1133, in run\n",
      "    value = future.result()\n",
      "  File \"/home/anhoang/.conda/envs/dask-test/lib/python3.6/site-packages/tornado/gen.py\", line 1141, in run\n",
      "    yielded = self.gen.throw(*exc_info)\n",
      "  File \"/home/anhoang/.conda/envs/dask-test/lib/python3.6/site-packages/distributed/scheduler.py\", line 2223, in handle_worker\n",
      "    yield self.handle_stream(comm=comm, extra={'worker': worker})\n",
      "  File \"/home/anhoang/.conda/envs/dask-test/lib/python3.6/site-packages/tornado/gen.py\", line 1133, in run\n",
      "    value = future.result()\n",
      "  File \"/home/anhoang/.conda/envs/dask-test/lib/python3.6/site-packages/tornado/gen.py\", line 1147, in run\n",
      "    yielded = self.gen.send(value)\n",
      "  File \"/home/anhoang/.conda/envs/dask-test/lib/python3.6/site-packages/distributed/core.py\", line 400, in handle_stream\n",
      "    handler(**merge(extra, msg))\n",
      "  File \"/home/anhoang/.conda/envs/dask-test/lib/python3.6/site-packages/distributed/scheduler.py\", line 2134, in handle_release_data\n",
      "    ws = self.workers[worker]\n",
      "KeyError: 'tcp://172.18.113.6:37171'\n",
      "Worker tcp://172.18.113.6:33597 restart in Job 7066871. This can be due to memory issue.\n",
      "Worker tcp://172.18.113.1:33579 restart in Job 7066848. This can be due to memory issue.\n",
      "Worker tcp://172.18.113.1:33579 restart in Job 7066848. This can be due to memory issue.\n",
      "distributed.utils - ERROR - Worker already exists tcp://172.18.113.1:33579\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/anhoang/.conda/envs/dask-test/lib/python3.6/site-packages/distributed/utils.py\", line 649, in log_errors\n",
      "    yield\n",
      "  File \"/home/anhoang/.conda/envs/dask-test/lib/python3.6/site-packages/distributed/scheduler.py\", line 1281, in add_worker\n",
      "    raise ValueError(\"Worker already exists %s\" % address)\n",
      "ValueError: Worker already exists tcp://172.18.113.1:33579\n",
      "distributed.core - ERROR - Worker already exists tcp://172.18.113.1:33579\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/anhoang/.conda/envs/dask-test/lib/python3.6/site-packages/distributed/core.py\", line 346, in handle_comm\n",
      "    result = yield result\n",
      "  File \"/home/anhoang/.conda/envs/dask-test/lib/python3.6/site-packages/tornado/gen.py\", line 1133, in run\n",
      "    value = future.result()\n",
      "  File \"/home/anhoang/.conda/envs/dask-test/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/home/anhoang/.conda/envs/dask-test/lib/python3.6/site-packages/distributed/scheduler.py\", line 1281, in add_worker\n",
      "    raise ValueError(\"Worker already exists %s\" % address)\n",
      "ValueError: Worker already exists tcp://172.18.113.1:33579\n",
      "Worker tcp://172.18.113.1:33579 restart in Job 7066848. This can be due to memory issue.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Worker tcp://172.18.113.4:33597 restart in Job 7066872. This can be due to memory issue.\n",
      "distributed.utils - ERROR - Worker already exists tcp://172.18.113.4:33597\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/anhoang/.conda/envs/dask-test/lib/python3.6/site-packages/distributed/utils.py\", line 649, in log_errors\n",
      "    yield\n",
      "  File \"/home/anhoang/.conda/envs/dask-test/lib/python3.6/site-packages/distributed/scheduler.py\", line 1281, in add_worker\n",
      "    raise ValueError(\"Worker already exists %s\" % address)\n",
      "ValueError: Worker already exists tcp://172.18.113.4:33597\n",
      "distributed.core - ERROR - Worker already exists tcp://172.18.113.4:33597\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/anhoang/.conda/envs/dask-test/lib/python3.6/site-packages/distributed/core.py\", line 346, in handle_comm\n",
      "    result = yield result\n",
      "  File \"/home/anhoang/.conda/envs/dask-test/lib/python3.6/site-packages/tornado/gen.py\", line 1133, in run\n",
      "    value = future.result()\n",
      "  File \"/home/anhoang/.conda/envs/dask-test/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/home/anhoang/.conda/envs/dask-test/lib/python3.6/site-packages/distributed/scheduler.py\", line 1281, in add_worker\n",
      "    raise ValueError(\"Worker already exists %s\" % address)\n",
      "ValueError: Worker already exists tcp://172.18.113.4:33597\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "A pipeline has not yet been optimized. Please call fit() first.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKilledWorker\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m~/.conda/envs/dask-test/lib/python3.6/site-packages/tpot/base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, features, target, sample_weight, groups)\u001b[0m\n\u001b[1;32m    660\u001b[0m                     \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbosity\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 661\u001b[0;31m                     \u001b[0mper_generation_function\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_periodic_pipeline\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    662\u001b[0m                 )\n",
      "\u001b[0;32m~/.conda/envs/dask-test/lib/python3.6/site-packages/tpot/gp_deap.py\u001b[0m in \u001b[0;36meaMuPlusLambda\u001b[0;34m(population, toolbox, mu, lambda_, cxpb, mutpb, ngen, pbar, stats, halloffame, verbose, per_generation_function)\u001b[0m\n\u001b[1;32m    229\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 230\u001b[0;31m     \u001b[0mfitnesses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtoolbox\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minvalid_ind\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    231\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mind\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfit\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minvalid_ind\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfitnesses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/dask-test/lib/python3.6/site-packages/tpot/base.py\u001b[0m in \u001b[0;36m_evaluate_individuals\u001b[0;34m(self, individuals, features, target, sample_weight, groups)\u001b[0m\n\u001b[1;32m   1223\u001b[0m                     \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msimplefilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ignore'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1224\u001b[0;31m                     \u001b[0mresult_score_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mresult_score_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1225\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/dask-test/lib/python3.6/site-packages/dask/base.py\u001b[0m in \u001b[0;36mcompute\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    397\u001b[0m     \u001b[0mpostcomputes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dask_postcompute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcollections\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 398\u001b[0;31m     \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mschedule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdsk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    399\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mrepack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpostcomputes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/dask-test/lib/python3.6/site-packages/distributed/client.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, dsk, keys, restrictions, loose_restrictions, resources, sync, asynchronous, direct, retries, priority, fifo_timeout, actors, **kwargs)\u001b[0m\n\u001b[1;32m   2331\u001b[0m                 results = self.gather(packed, asynchronous=asynchronous,\n\u001b[0;32m-> 2332\u001b[0;31m                                       direct=direct)\n\u001b[0m\u001b[1;32m   2333\u001b[0m             \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/dask-test/lib/python3.6/site-packages/distributed/client.py\u001b[0m in \u001b[0;36mgather\u001b[0;34m(self, futures, errors, maxsize, direct, asynchronous)\u001b[0m\n\u001b[1;32m   1655\u001b[0m                              \u001b[0mdirect\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdirect\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal_worker\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlocal_worker\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1656\u001b[0;31m                              asynchronous=asynchronous)\n\u001b[0m\u001b[1;32m   1657\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/dask-test/lib/python3.6/site-packages/distributed/client.py\u001b[0m in \u001b[0;36msync\u001b[0;34m(self, func, *args, **kwargs)\u001b[0m\n\u001b[1;32m    675\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 676\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0msync\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/dask-test/lib/python3.6/site-packages/distributed/utils.py\u001b[0m in \u001b[0;36msync\u001b[0;34m(loop, func, *args, **kwargs)\u001b[0m\n\u001b[1;32m    276\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 277\u001b[0;31m         \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    278\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/dask-test/lib/python3.6/site-packages/six.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(tp, value, tb)\u001b[0m\n\u001b[1;32m    692\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 693\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    694\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/dask-test/lib/python3.6/site-packages/distributed/utils.py\u001b[0m in \u001b[0;36mf\u001b[0;34m()\u001b[0m\n\u001b[1;32m    261\u001b[0m                 \u001b[0mfuture\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_timeout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimedelta\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseconds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m             \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32myield\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    263\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/dask-test/lib/python3.6/site-packages/tornado/gen.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1132\u001b[0m                     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1133\u001b[0;31m                         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1134\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/dask-test/lib/python3.6/site-packages/tornado/gen.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1140\u001b[0m                         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1141\u001b[0;31m                             \u001b[0myielded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthrow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1142\u001b[0m                         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/dask-test/lib/python3.6/site-packages/distributed/client.py\u001b[0m in \u001b[0;36m_gather\u001b[0;34m(self, futures, errors, direct, local_worker)\u001b[0m\n\u001b[1;32m   1496\u001b[0m                                         \u001b[0mexception\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1497\u001b[0;31m                                         traceback)\n\u001b[0m\u001b[1;32m   1498\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0merrors\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'skip'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/dask-test/lib/python3.6/site-packages/six.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(tp, value, tb)\u001b[0m\n\u001b[1;32m    692\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 693\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    694\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKilledWorker\u001b[0m: ('decisiontreeregressor-d52db28bb910a019682ed1346fbeb18a', 'tcp://172.18.113.1:33579')",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-c5bcc440217f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.conda/envs/dask-test/lib/python3.6/site-packages/tpot/base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, features, target, sample_weight, groups)\u001b[0m\n\u001b[1;32m    691\u001b[0m                     \u001b[0;31m# raise the exception if it's our last attempt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    692\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mattempt\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mattempts\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 693\u001b[0;31m                         \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    694\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    695\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/dask-test/lib/python3.6/site-packages/tpot/base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, features, target, sample_weight, groups)\u001b[0m\n\u001b[1;32m    682\u001b[0m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    683\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 684\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_top_pipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    685\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_summary_of_best_pipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    686\u001b[0m                     \u001b[0;31m# Delete the temporary cache before exiting\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/dask-test/lib/python3.6/site-packages/tpot/base.py\u001b[0m in \u001b[0;36m_update_top_pipeline\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    756\u001b[0m             \u001b[0;31m# If user passes CTRL+C in initial generation, self._pareto_front (halloffame) shoule be not updated yet.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    757\u001b[0m             \u001b[0;31m# need raise RuntimeError because no pipeline has been optimized\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 758\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'A pipeline has not yet been optimized. Please call fit() first.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    759\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    760\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_summary_of_best_pipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: A pipeline has not yet been optimized. Please call fit() first."
     ]
    }
   ],
   "source": [
    "tp.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tp.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1024\n"
     ]
    }
   ],
   "source": [
    "!ulimit -n\n",
    "#!ulimit -Sn 10000"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dask-test",
   "language": "python",
   "name": "dask-test"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
